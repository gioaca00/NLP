{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cac50491",
      "metadata": {
        "id": "cac50491"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this practical part of the assignment, you will implement a model that takes a sentence as input and predicts the most likely CFG parse tree given that sentence:\n",
        "$$\n",
        "\\mathbf{t} = \\text{argmax}_\\mathbf{t}P(\\mathbf{t}|\\mathbf{s})\n",
        "$$\n",
        "\n",
        "\n",
        "You will do this by converting the words into embeddings, and then implementing the CKY algorithm on top of an LSTM which you will train end-to-end."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "qikEanUG5tFC",
      "metadata": {
        "id": "qikEanUG5tFC"
      },
      "source": [
        "## Dependencies\n",
        "Please run the following cell to install the necessary dependencies for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HDZd3lnK5u34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDZd3lnK5u34",
        "outputId": "20390fb0-e108-408c-ced7-743c2e94289a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dynet in /usr/local/lib/python3.8/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dynet) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from dynet) (0.29.32)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: svgling in /usr/local/lib/python3.8/dist-packages (0.3.1)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.8/dist-packages (from svgling) (1.4.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install dynet\n",
        "!pip install svgling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "OEeO7orj5xdz",
      "metadata": {
        "id": "OEeO7orj5xdz"
      },
      "source": [
        "Also, please download [this folder](https://drive.google.com/drive/folders/1FgT2bQdH0eCDDaqkDGk7hORUUDGd6a9t?usp=sharing) and upload it to your google drive, and then run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZX7mMf0Z5z85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX7mMf0Z5z85",
        "outputId": "dd642df7-4b1b-4dbd-dc3d-de7620afc42a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/nlp-h2022-parsing\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/nlp-h2022-parsing'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "842646d2",
      "metadata": {
        "id": "842646d2"
      },
      "source": [
        "# 1. Training Data\n",
        "\n",
        "In this section, you will download, interact with, and clean the data which you will use to train and test your model. We will be using the Penn Treebank, an corpus of sentences annotated with Part of Speech tags and CFG parse trees. For ease of computation under limited resources, we will be using a fraction (10%) of the treebank corpus which is distributed with the **nltk** python library."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "41a4c4e6",
      "metadata": {
        "id": "41a4c4e6"
      },
      "source": [
        "## The Raw Data\n",
        "Download the data by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13da9ebc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13da9ebc",
        "outputId": "0025ea89-3617-4b06-e873-f89788175c7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
        "nltk.download('treebank')\n",
        "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a0bf62ed",
      "metadata": {
        "id": "a0bf62ed"
      },
      "source": [
        "Have a look at the first few examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106118f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "106118f0",
        "outputId": "0c43642b-1b6a-4ca2-9b2a-0291f5da1725"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])]),\n",
              " Tree('S', [Tree('NP-SBJ-1', [Tree('NP', [Tree('NNP', ['Rudolph']), Tree('NNP', ['Agnew'])]), Tree(',', [',']), Tree('UCP', [Tree('ADJP', [Tree('NP', [Tree('CD', ['55']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree('CC', ['and']), Tree('NP', [Tree('NP', [Tree('JJ', ['former']), Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NNP', ['Consolidated']), Tree('NNP', ['Gold']), Tree('NNP', ['Fields']), Tree('NNP', ['PLC'])])])])]), Tree(',', [','])]), Tree('VP', [Tree('VBD', ['was']), Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])])]), Tree('.', ['.'])])]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[1:3]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c5177c2f",
      "metadata": {
        "id": "c5177c2f"
      },
      "source": [
        "The parenthes encode a tree structure which can be pretty printed by calling a single example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09742f39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "09742f39",
        "outputId": "c02d0f4c-cec9-4b63-dac9-1ab2d13034a1"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg baseProfile=\"full\" height=\"408px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,1544.0,408.0\" width=\"1544px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"56.9948%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"15.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"64.7059%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lorillard</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.3529%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.2941%\" x=\"64.7059%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Inc.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.3529%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.72727%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"15.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.8182%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"79.0909%\" x=\"18.1818%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"12.6437%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">unit</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.32184%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40.2299%\" x=\"12.6437%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"11.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.71429%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"88.5714%\" x=\"11.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"54.8387%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York-based</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"54.8387%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Loews</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.129%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Corp.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.7586%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"47.1264%\" x=\"52.8736%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">SBAR</text></svg><svg width=\"19.5122%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WHNP-2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WDT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">that</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.7561%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.4878%\" x=\"19.5122%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"24.2424%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-NONE-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">*T*-2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.1212%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"75.7576%\" x=\"24.2424%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"28%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">makes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72%\" x=\"28%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Kent</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarettes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.1212%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.7561%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.4368%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"97.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.4974%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.4508%\" x=\"56.9948%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"11.25%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">stopped</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.625%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"88.75%\" x=\"11.25%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"9.85915%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">using</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.92958%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"18.3099%\" x=\"9.85915%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">crocidolite</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.0141%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"57.7465%\" x=\"28.169%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP-LOC-CLR</text></svg><svg width=\"9.7561%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.87805%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90.2439%\" x=\"9.7561%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.2162%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PRP$</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">its</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.10811%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.7297%\" x=\"16.2162%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Micronite</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.0811%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.7297%\" x=\"45.9459%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarette</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.8108%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"24.3243%\" x=\"75.6757%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">filters</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.8378%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.878%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.0423%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"14.0845%\" x=\"85.9155%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP-TMP</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">1956</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.9577%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.625%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.7202%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"1.5544%\" x=\"98.4456%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"99.2228%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
            ],
            "text/plain": [
              "Tree('S', [Tree('NP-SBJ', [Tree('NP', [Tree('NNP', ['Lorillard']), Tree('NNP', ['Inc.'])]), Tree(',', [',']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['unit'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('ADJP', [Tree('JJ', ['New']), Tree('JJ', ['York-based'])]), Tree('NNP', ['Loews']), Tree('NNP', ['Corp.'])])]), Tree('SBAR', [Tree('WHNP-2', [Tree('WDT', ['that'])]), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*T*-2'])]), Tree('VP', [Tree('VBZ', ['makes']), Tree('NP', [Tree('NNP', ['Kent']), Tree('NNS', ['cigarettes'])])])])])]), Tree(',', [','])]), Tree('VP', [Tree('VBD', ['stopped']), Tree('VP', [Tree('VBG', ['using']), Tree('NP', [Tree('NN', ['crocidolite'])]), Tree('PP-LOC-CLR', [Tree('IN', ['in']), Tree('NP', [Tree('PRP$', ['its']), Tree('NN', ['Micronite']), Tree('NN', ['cigarette']), Tree('NNS', ['filters'])])]), Tree('PP-TMP', [Tree('IN', ['in']), Tree('NP', [Tree('CD', ['1956'])])])])]), Tree('.', ['.'])])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "27023347",
      "metadata": {
        "id": "27023347"
      },
      "source": [
        "## Cleaning the data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "46f4c176",
      "metadata": {
        "id": "46f4c176"
      },
      "source": [
        "\n",
        "\n",
        "Next, we will prepare the data so it can be used to train our parser. For this part, please make yourself familiar with the [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html) module.\n",
        "\n",
        "Look at the following subtree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361ba371",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "361ba371",
        "outputId": "75408fa4-fc0a-4212-f624-3bf328bad0d7"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,880.0,360.0\" width=\"880px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"15.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"64.7059%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lorillard</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.3529%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.2941%\" x=\"64.7059%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Inc.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.3529%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.72727%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"15.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.8182%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"79.0909%\" x=\"18.1818%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"12.6437%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">unit</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.32184%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40.2299%\" x=\"12.6437%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"11.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.71429%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"88.5714%\" x=\"11.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"54.8387%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York-based</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"54.8387%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Loews</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.129%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Corp.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.7586%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"47.1264%\" x=\"52.8736%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">SBAR</text></svg><svg width=\"19.5122%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WHNP-2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WDT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">that</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.7561%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.4878%\" x=\"19.5122%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"24.2424%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-NONE-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">*T*-2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.1212%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"75.7576%\" x=\"24.2424%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"28%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">makes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72%\" x=\"28%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Kent</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarettes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.1212%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.7561%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.4368%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"97.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
            ],
            "text/plain": [
              "Tree('NP-SBJ', [Tree('NP', [Tree('NNP', ['Lorillard']), Tree('NNP', ['Inc.'])]), Tree(',', [',']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['unit'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('ADJP', [Tree('JJ', ['New']), Tree('JJ', ['York-based'])]), Tree('NNP', ['Loews']), Tree('NNP', ['Corp.'])])]), Tree('SBAR', [Tree('WHNP-2', [Tree('WDT', ['that'])]), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*T*-2'])]), Tree('VP', [Tree('VBZ', ['makes']), Tree('NP', [Tree('NNP', ['Kent']), Tree('NNS', ['cigarettes'])])])])])]), Tree(',', [','])])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[5][0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4e7e23fb",
      "metadata": {
        "id": "4e7e23fb"
      },
      "source": [
        "First, note that nonterminals can have a variable number of children. However, in order for CKY to work, we require the data to be in Chomsky Normal Form (CNF), i.e. it needs to be binarized. \n",
        "We also want to simplify tags that have hyphens in them, and filter out -NONE- tags (which are used e.g. to indicate relative clauses).\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9bc669f5",
      "metadata": {
        "id": "9bc669f5"
      },
      "source": [
        "### 1.1 Removing -NONE-, -RCB-, and -LRB- tags\n",
        "We want to remove `-NONE-`, `-LRB-` and `-RCB-` tags. For the sake of simplicity, we will remove any tree that contains these tags. Write a method that returns True if a tree passed to it contains such tags. In a comment (without implementing the code), give two other ways `-NONE-` tags could be handled more data efficiently without affecting the grammaticality of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d55a1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12d55a1f",
        "outputId": "e2866b68-a4bf-46cc-a570-903a08e5b734"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import Tree\n",
        "\n",
        "bad_tags = ['-NONE-', '-LRB-', '-RCB-']\n",
        "\n",
        "def contains_none_tags(tree):\n",
        "    \"\"\"\n",
        "    parameters: \n",
        "        tree: parse tree\n",
        "    \n",
        "    returns: \n",
        "        True iff the tree contains NONE, LRB or RCB tags.\n",
        "    \"\"\"\n",
        "    if tree.label() in bad_tags:\n",
        "      return True\n",
        "\n",
        "    result = False\n",
        "    for node in tree:\n",
        "      if node not in tree.leaves():\n",
        "        result = result or contains_none_tags(node)\n",
        "    return result\n",
        "    '''\n",
        "    Alternative method:\n",
        "    1) I could replace every -NONE- label with an empty string\n",
        "    2) Collapse unary branches in one node in a way similar to 1.3, to delete the bad tagged words\n",
        "    '''\n",
        "    \n",
        "contains_none_tags(treebank.parsed_sents()[5][0]) # this should return True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "aa0ee52e",
      "metadata": {
        "id": "aa0ee52e"
      },
      "source": [
        "### 1.2 Simplifying Functional Tags\n",
        "Write a method that takes in tags and only keeps the part before the first hyphen if it is hyphenated - e.g. `NP-SBJ` should become `NP`. Then write a method that traverses a tree and updates its tags in place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003d7dd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "003d7dd4",
        "outputId": "dc8020da-ec26-49cf-d0ca-3dd6fc1d78bf"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,360.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"81.1765%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"62%\" x=\"38%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"38.7097%\" x=\"38.7097%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.8824%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.52941%\" x=\"96.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
            ],
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def simplify_functional_tag(tag):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        tag: string\n",
        "    \n",
        "    returns:\n",
        "        the tag up to the first hyphen\n",
        "    \n",
        "    \"\"\"\n",
        "    if tag in bad_tags:\n",
        "        return tag\n",
        "\n",
        "    if '-' in tag:\n",
        "      tag = tag.split('-')[0]\n",
        "        \n",
        "    return tag\n",
        "\n",
        "def simplify_tags(tree):\n",
        "    \"\"\"\n",
        "    Traverses a parse tree and simplifies tags containing hyphens\n",
        "    \n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "        \n",
        "    returns: \n",
        "        parse tree with simplified tags (up to the first hyphen)\n",
        "    \"\"\"\n",
        "\n",
        "    tree.set_label(simplify_functional_tag(tree.label()))\n",
        "    for node in tree:\n",
        "      if node not in tree.leaves():\n",
        "        simplify_tags(node)\n",
        "    return tree\n",
        "    \n",
        "simplified_tree = treebank.parsed_sents()[1].copy(deep=True)\n",
        "simplify_tags(simplified_tree)\n",
        "simplified_tree"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7d0b3cdf",
      "metadata": {
        "id": "7d0b3cdf"
      },
      "source": [
        "### 1.3 Binarizing the Parse Trees\n",
        "To remove unary derivations and convert the training trees to binary trees, we will use the functions `collapse_unary` and `chomsky_normal_form` in [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html). Write down the call you will make using horizontal markov smoothing of 1 and vertical markov smoothing of 0, factoring right, and using ^ for parent and | for child. Explain the meaning and the purpose of these parameters in a comment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba69bf6",
      "metadata": {
        "id": "1ba69bf6"
      },
      "outputs": [],
      "source": [
        "from nltk.tree import collapse_unary, chomsky_normal_form\n",
        "\n",
        "def binarize(tree):\n",
        "    \"\"\"\n",
        "    Collapses unary productions and binarizes a parse tree in place.\n",
        "    \n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "        \n",
        "    returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    tree.collapse_unary()\n",
        "    tree.chomsky_normal_form(factor=\"right\", horzMarkov=1, vertMarkov=0, childChar=\"|\", parentChar=\"^\")\n",
        "    return tree\n",
        "    '''\n",
        "    What the parameters mean is perfectly explained in a comment in the NLTK documentation, I quote from there:\n",
        "    :param factor: Right or left factoring method (default = \"right\")\n",
        "    :param horzMarkov: Markov order for sibling smoothing in artificial nodes (None (default) = include all siblings)\n",
        "    :param vertMarkov: Markov order for parent smoothing (0 (default) = no vertical annotation)\n",
        "    :param childChar: A string used in construction of the artificial nodes, separating the head of the\n",
        "                      original subtree from the child nodes that have yet to be expanded (default = \"|\")\n",
        "    :param parentChar: A string used to separate the node representation from its vertical annotation\n",
        "    '''\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d60ddd21",
      "metadata": {
        "id": "d60ddd21"
      },
      "source": [
        "### 1.4 Run Data Preprocessing\n",
        "\n",
        "Bringing all of these together, write a method that takes a set of trees and returns a list of (copied) cleaned trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8b80f4",
      "metadata": {
        "id": "9d8b80f4"
      },
      "outputs": [],
      "source": [
        "def clean_trees(trees):\n",
        "    \"\"\"\n",
        "    Cleans parse trees from the penn treebank by performing tag simplification, \n",
        "        binarization, and filtering out trees with NONE tags.\n",
        "    \n",
        "    parameters:\n",
        "        trees: parse trees\n",
        "        \n",
        "    returns:\n",
        "        list of cleaned trees\n",
        "    \"\"\"\n",
        "\n",
        "    lst = []\n",
        "    for tree in trees:\n",
        "      if contains_none_tags(tree) != True:\n",
        "        tree = simplify_tags(tree)\n",
        "        tree = binarize(tree)\n",
        "        lst.append(tree)\n",
        "    return lst\n",
        "      \n",
        "    \n",
        "trees_cleaned = clean_trees(treebank.parsed_sents())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6S6od-InPnWY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "6S6od-InPnWY",
        "outputId": "ba558a0d-4e6c-4eaa-b519-b4e7a7c9c41e"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg baseProfile=\"full\" height=\"504px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,856.0,504.0\" width=\"856px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"35.514%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"42.1053%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Pierre</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"57.8947%\" x=\"42.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;,&gt;</text></svg><svg width=\"13.6364%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.81818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"86.3636%\" x=\"13.6364%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;ADJP&gt;</text></svg><svg width=\"84.2105%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"68.75%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">61</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">years</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.375%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"31.25%\" x=\"68.75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">old</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.375%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"15.7895%\" x=\"84.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.1053%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.8182%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.0526%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.757%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"64.486%\" x=\"35.514%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S|&lt;VP&gt;</text></svg><svg width=\"95.6522%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"9.09091%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">MD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">will</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.54545%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90.9091%\" x=\"9.09091%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"10%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">join</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90%\" x=\"10%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP|&lt;NP&gt;</text></svg><svg width=\"22.2222%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">board</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.1111%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.7778%\" x=\"22.2222%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP|&lt;PP&gt;</text></svg><svg width=\"76.1905%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"12.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">as</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"87.5%\" x=\"12.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"85.7143%\" x=\"14.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;JJ&gt;</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">nonexecutive</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">director</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.1429%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.0952%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.8095%\" x=\"76.1905%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"60%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Nov.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40%\" x=\"60%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">29</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0952%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.1111%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.5455%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.8261%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.34783%\" x=\"95.6522%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.8261%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.757%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
            ],
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]), Tree('NP|<,>', [Tree(',', [',']), Tree('NP|<ADJP>', [Tree('ADJP', [Tree('NP', [Tree('CD', ['61']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree(',', [','])])])]), Tree('S|<VP>', [Tree('VP', [Tree('MD', ['will']), Tree('VP', [Tree('VB', ['join']), Tree('VP|<NP>', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['board'])]), Tree('VP|<PP>', [Tree('PP', [Tree('IN', ['as']), Tree('NP', [Tree('DT', ['a']), Tree('NP|<JJ>', [Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])])])]), Tree('NP', [Tree('NNP', ['Nov.']), Tree('CD', ['29'])])])])])]), Tree('.', ['.'])])])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trees_cleaned[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5d3ed7e9",
      "metadata": {
        "id": "5d3ed7e9"
      },
      "source": [
        "Now we can write the cleaned data to the disk to use as training and test data later (using an 90:10 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552b40d7",
      "metadata": {
        "id": "552b40d7"
      },
      "outputs": [],
      "source": [
        "def flatten(tree):\n",
        "    return tree._pformat_flat(\"\", \"()\", False)\n",
        "\n",
        "trees_train = trees_cleaned[:886]\n",
        "trees_test = trees_cleaned[886:]\n",
        "\n",
        "with open(\"data/train.clean\", \"w\") as f:\n",
        "    for tree in trees_train:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")\n",
        "        \n",
        "with open(\"data/test.clean\", \"w\") as f:\n",
        "    for tree in trees_test:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cb16456e",
      "metadata": {
        "id": "cb16456e"
      },
      "source": [
        "# 2. Neural Constituency Parser"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6c51466e",
      "metadata": {
        "id": "6c51466e"
      },
      "source": [
        "Now we want to train our model to parse from scratch, by providing it with training examples and optimizing it.\n",
        "We will use a bidirectional LSTM."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "47a4ed8e",
      "metadata": {
        "id": "47a4ed8e"
      },
      "source": [
        "## Defining the vocabulary\n",
        "First, load the training and test data we created in part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5ea1fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e5ea1fa",
        "outputId": "bbd57413-3bf7-4e87-f589-48557771c860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/train.clean\n",
            "Loaded 886 training examples.\n",
            "Loaded 100 test examples.\n",
            "Processing trees for training...\n"
          ]
        }
      ],
      "source": [
        "from src import trees\n",
        "\n",
        "train_path = \"data/train.clean\"\n",
        "test_path = \"data/test.clean\"\n",
        "print(train_path)\n",
        "train_treebank = trees.load_trees(train_path)\n",
        "test_treebank = trees.load_trees(test_path)\n",
        "\n",
        "print(f\"Loaded {len(train_treebank)} training examples.\")\n",
        "print(f\"Loaded {len(test_treebank)} test examples.\")\n",
        "\n",
        "print(\"Processing trees for training...\")\n",
        "train_parse = [tree.convert() for tree in train_treebank]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "79309372",
      "metadata": {
        "id": "79309372"
      },
      "source": [
        "Then, we collect the vocabulary for words, tags, and labels from the training data, creating a reverse index to look up the index of words in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649df1a4",
      "metadata": {
        "id": "649df1a4"
      },
      "outputs": [],
      "source": [
        "from src import vocabulary\n",
        "\n",
        "START = \"<START>\"\n",
        "STOP = \"<STOP>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "tag_vocab = vocabulary.Vocabulary()\n",
        "tag_vocab.index(START)\n",
        "tag_vocab.index(STOP)\n",
        "\n",
        "word_vocab = vocabulary.Vocabulary()\n",
        "word_vocab.index(START)\n",
        "word_vocab.index(STOP)\n",
        "word_vocab.index(UNK)\n",
        "\n",
        "label_vocab = vocabulary.Vocabulary()\n",
        "label_vocab.index(())\n",
        "\n",
        "for tree in train_parse:\n",
        "    nodes = [tree]\n",
        "    while nodes:\n",
        "        node = nodes.pop()\n",
        "        if isinstance(node, trees.InternalParseNode):\n",
        "            label_vocab.index(node.label)\n",
        "            nodes.extend(reversed(node.children))\n",
        "        else:\n",
        "            tag_vocab.index(node.tag)\n",
        "            word_vocab.index(node.word)\n",
        "\n",
        "tag_vocab.freeze()\n",
        "word_vocab.freeze()\n",
        "label_vocab.freeze()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f0fefeb6",
      "metadata": {
        "id": "f0fefeb6"
      },
      "source": [
        "## Defining the model\n",
        "Now, we will define the neural network model that will predict label scores for spans. The reference implementation uses a bidirectional LSTM which you can define using dynet's [BiRNNBuilder class](https://dynet.readthedocs.io/en/latest/python_ref.html#dynet.BiRNNBuilder). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4100b9",
      "metadata": {
        "id": "6e4100b9"
      },
      "outputs": [],
      "source": [
        "import dynet as dy\n",
        "from src.util import Feedforward\n",
        "\n",
        "dy.reset_random_seed(42)\n",
        "\n",
        "# Create a dynet model\n",
        "model = dy.ParameterCollection()\n",
        "parser_model = model.add_subcollection(\"Parser\")\n",
        "\n",
        "batch_size = 10\n",
        "tag_embedding_dim = 50\n",
        "word_embedding_dim = 100\n",
        "lstm_layers = 2\n",
        "lstm_dim = 250\n",
        "label_hidden_dim = 250\n",
        "dropout = 0.4\n",
        "\n",
        "tag_embeddings = parser_model.add_lookup_parameters((tag_vocab.size, tag_embedding_dim))\n",
        "word_embeddings = parser_model.add_lookup_parameters((word_vocab.size, word_embedding_dim))\n",
        "\n",
        "# Create a lstm using the dynet BiRNNBuilder\n",
        "lstm = dy.BiRNNBuilder(\n",
        "    lstm_layers,\n",
        "    tag_embedding_dim + word_embedding_dim,\n",
        "    2 * lstm_dim,\n",
        "    parser_model,\n",
        "    dy.VanillaLSTMBuilder)\n",
        "\n",
        "# Define a Feedforward neural net that predicts the label probabilities given lstm outputs from a sentence\n",
        "f_label = Feedforward(parser_model, 2 * lstm_dim, [label_hidden_dim], label_vocab.size - 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e9fdaa53",
      "metadata": {
        "id": "e9fdaa53"
      },
      "source": [
        "## 2.1 Generating Embeddings\n",
        "\n",
        "Next we need to convert the words and tags into embeddings that can be fed to the LSTM. Implement the following method.\n",
        "Unknown words should get the embedding of the UNK word.\n",
        "\n",
        "Hint: use the reverse index methods `tag_vocab.index()` and `word_vocab.index()` methods from `vocabulary.py` to find the keys of words and tags in the respective embedding dicts created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3895e3",
      "metadata": {
        "id": "2a3895e3"
      },
      "outputs": [],
      "source": [
        "def convert_to_embeddings(sentence):\n",
        "    \"\"\"\n",
        "    Converts a sentence consisting of tags and words into embeddings. \n",
        "        Replaces words not in the vocabulary with with the UNK placeholder.\n",
        "    \n",
        "    params:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "    \n",
        "    return:\n",
        "        dy expression containing a concatenation of all tag embedding/word embedding pairs\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for tag, word in [(START, START)] + sentence + [(STOP, STOP)]:\n",
        "\n",
        "        try:\n",
        "          tag_key = tag_vocab.index(tag)\n",
        "          word_key = word_vocab.index(word)\n",
        "        except:\n",
        "          tag_key = tag_vocab.index(tag)\n",
        "          word_key = word_vocab.index(UNK)\n",
        "        \n",
        "        tag_embedding = dy.lookup(tag_embeddings,tag_key)\n",
        "        word_embedding = dy.lookup(word_embeddings,word_key)\n",
        "\n",
        "        \n",
        "        embeddings.append(dy.concatenate([tag_embedding, word_embedding]))   \n",
        "    return embeddings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "FedYhfo9q8Df",
      "metadata": {
        "id": "FedYhfo9q8Df"
      },
      "source": [
        "To test your code, run the following cell on the sentence `The boy ate a pie` with tags ['DT', 'NN', 'VBZ' 'DT', 'NN']:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09cTYZ1Tq8de",
      "metadata": {
        "id": "09cTYZ1Tq8de"
      },
      "outputs": [],
      "source": [
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "embeddings = convert_to_embeddings(sentence)\n",
        "assert len(embeddings)==7\n",
        "assert len(embeddings[0].value())==150\n",
        "assert embeddings[5].value() == dy.concatenate(\n",
        "    [tag_embeddings[tag_vocab.index('NN')],\n",
        "     word_embeddings[word_vocab.index(UNK)]]).value()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b5eb2e53",
      "metadata": {
        "id": "b5eb2e53"
      },
      "source": [
        "We can now use the above method to get the lstm outputs for the whole sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d09015f",
      "metadata": {
        "id": "3d09015f"
      },
      "outputs": [],
      "source": [
        "def get_lstm_outputs(sentence, is_train):\n",
        "    \"\"\"\n",
        "    Gets the outputs of the lstm for a given sentence.\n",
        "    \n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        \n",
        "    returns:\n",
        "        lstm_outputs\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    if is_train:\n",
        "        lstm.set_dropout(dropout)\n",
        "    else:\n",
        "        lstm.disable_dropout()\n",
        "    \n",
        "    # Get the tag and word embeddings for the sentence\n",
        "    embeddings = convert_to_embeddings(sentence)\n",
        "    \n",
        "    # Get the output of the LSTM given the embedded sentence\n",
        "    lstm_outputs = lstm.transduce(embeddings)\n",
        "        \n",
        "    return lstm_outputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6bcfc975",
      "metadata": {
        "id": "6bcfc975"
      },
      "source": [
        "The following two methods are helper methods which compute the scores for each label given a span."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8314af",
      "metadata": {
        "id": "bf8314af"
      },
      "outputs": [],
      "source": [
        "from src.util import augment\n",
        "\n",
        "def get_span_encoding(left, right, lstm_outputs):\n",
        "    \"\"\"\n",
        "    Computes the encoding of a sentence span (substring between two indices) \n",
        "        given the forward and backward outputs in the LSTM.\n",
        "    \n",
        "    parameters:\n",
        "        left: left span index\n",
        "        right: right span index\n",
        "    \n",
        "    returns:\n",
        "        encoding of the span\n",
        "    \"\"\"\n",
        "    forward = (\n",
        "        lstm_outputs[right][:lstm_dim] -\n",
        "        lstm_outputs[left][:lstm_dim])\n",
        "    backward = (\n",
        "        lstm_outputs[left + 1][lstm_dim:] -\n",
        "        lstm_outputs[right + 1][lstm_dim:])\n",
        "    return dy.concatenate([forward, backward])\n",
        "\n",
        "def get_label_scores(left, right, lstm_outputs, gold, force_gold):\n",
        "    \"\"\"\n",
        "    Computes the best label for a given span and its score.\n",
        "    \n",
        "    parameters:\n",
        "        left: left index of the span\n",
        "        right: right index of the span\n",
        "        lstm_outputs: outputs of the lstm when given the sentence\n",
        "        gold reference parse tree for the sentence\n",
        "        force_gold: True if method should construct the gold parse tree \n",
        "          and compute its score\n",
        "        \n",
        "    returns:\n",
        "        (label, score):\n",
        "            label: the highest scoring label if force_gold is False, \n",
        "              or the gold label if force_gold is true\n",
        "            score: the score of the label\n",
        "    \"\"\"\n",
        "    is_train = gold is not None\n",
        "\n",
        "    label_scores = f_label(get_span_encoding(left, right, lstm_outputs))\n",
        "    label_scores = dy.concatenate([dy.zeros(1), label_scores])\n",
        "    \n",
        "    if is_train:\n",
        "        oracle_label = gold.oracle_label(left, right)\n",
        "        oracle_label_index = label_vocab.index(oracle_label)\n",
        "    \n",
        "    if force_gold:\n",
        "        label_score = label_scores[oracle_label_index]\n",
        "        label = oracle_label\n",
        "        \n",
        "    else:\n",
        "        if is_train:\n",
        "            label_scores = augment(label_scores, oracle_label_index)\n",
        "        label_scores_np = label_scores.npvalue()\n",
        "        span = right - left\n",
        "        argmax_label_index = int(\n",
        "                        label_scores_np.argmax() if span < len(sentence) else\n",
        "                        label_scores_np[1:].argmax() + 1)\n",
        "        label = label_vocab.value(argmax_label_index)\n",
        "        label_score = label_scores[argmax_label_index]\n",
        "    return label, label_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fadb8972",
      "metadata": {
        "id": "fadb8972"
      },
      "source": [
        "## 2.2 CKY with estimated label probabilites\n",
        "Now we can implement the parser method. It works like CKY, with some additions.\n",
        "\n",
        "During training, the `gold` parameter is set, representing the reference parse tree. During inference, this is not set and the method simply returns the best scoring parse tree.\n",
        "\n",
        "Your task is to implement the CKY algorithm, iterating through spans and for each pair of span indices dynamically calculate scores and parse trees:\n",
        "1. Use the method `get_label_scores(left, right, lstm_outputs, gold, force_gold)` to get the scores for each label corresponding to the given span (left, right).\n",
        "2. Find the best place to split a given span into two subspans given their respective label scores. (If `force_gold` is set, use the method `tree.oracle_splits(left, right)` from `trees.py` to get the split positions, and use the first of them as the index to split the tree.)\n",
        "3. Calculate the score of the label when splitting at the best index found above and put it into the scores `chart`.\n",
        "4. Get the subtrees for the span and split position, and put the resulting new subtree into the `parse_trees` dict.\n",
        "\n",
        "*Hint: the label scores are stored as dynet expressions, use `.value()` to get the score value.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb42e8f",
      "metadata": {
        "id": "4fb42e8f"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize.util import spans_to_relative\n",
        "from src import trees\n",
        "\n",
        "def parse(sentence, gold=None, force_gold=False):\n",
        "    \"\"\"\n",
        "    Generates the best scoring parse tree for a given sentence.\n",
        "    \n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold: gold reference parse tree for the sentence\n",
        "        force_gold: If true, method will construct the gold parse tree \n",
        "            and compute its score, otherwise it will compute the \n",
        "            best scoring parse tree.\n",
        "        \n",
        "    returns:\n",
        "        (tree, score): \n",
        "            tree: constructed best or gold parse tree\n",
        "            score: score of the constructed parse tree\n",
        "    \"\"\"\n",
        "    N = len(sentence)\n",
        "    \n",
        "    chart = {}\n",
        "    parse_trees = {}\n",
        "    \n",
        "    is_train = gold is not None\n",
        "    lstm_outputs = get_lstm_outputs(sentence, is_train)\n",
        "    for i in range(N):\n",
        "        tag, word = sentence[i]\n",
        "        label, score = get_label_scores(i, i + 1, lstm_outputs, gold, force_gold)\n",
        "        # tree\n",
        "        tree = trees.LeafParseNode(i, tag, word)\n",
        "        if label:\n",
        "          tree = trees.InternalParseNode(label, [tree])\n",
        "        # score\n",
        "        parse_trees[i, i + 1] = [tree]\n",
        "        chart[i, i + 1] = score\n",
        "    for span in range(1, N):\n",
        "        for i in range(N - span):\n",
        "            # initialize\n",
        "            j = i + span + 1\n",
        "            score = 0\n",
        "            best_value = 0\n",
        "            best_chart = 0\n",
        "            flag = 0\n",
        "            # Get the label scores for the span\n",
        "            label, span_score = get_label_scores(i, j, lstm_outputs, gold, force_gold)\n",
        "            if force_gold == True:\n",
        "              pos = gold.oracle_splits(i,j)\n",
        "              best_chart = span_score + chart[i,pos[0]] + chart[pos[0],j]\n",
        "              new_node = parse_trees[i,pos[0]] + parse_trees[pos[0],j]\n",
        "            else:\n",
        "              for k in range(i+1, j):\n",
        "                # Compute the score for the left child\n",
        "                left_child = parse_trees[i,k]\n",
        "                left_score = chart[i,k]\n",
        "                \n",
        "                # Compute the score for the right child\n",
        "                right_child = parse_trees[k,j]\n",
        "                right_score = chart[k,j]\n",
        "                \n",
        "                # Choose the best score and tree\n",
        "                score = span_score + left_score + right_score\n",
        "\n",
        "                if flag == 0:\n",
        "                  flag = 1\n",
        "                  new_node = left_child + right_child\n",
        "                \n",
        "                if best_value<score.value():\n",
        "                  best_value = score.value()\n",
        "                  best_chart = score\n",
        "                  new_node = left_child + right_child\n",
        "            if label:\n",
        "              tree = trees.InternalParseNode(label, new_node)\n",
        "              parse_trees[i,j] = [tree]\n",
        "            else:\n",
        "              parse_trees[i,j] = new_node\n",
        "            chart[i,j] = best_chart\n",
        "            \n",
        "    assert len(parse_trees[0, N]) == 1        \n",
        "    tree = parse_trees[0, N][0]\n",
        "    score = chart[0, N]\n",
        "    return tree, score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "oxIxXPz_rro3",
      "metadata": {
        "id": "oxIxXPz_rro3"
      },
      "source": [
        "Test your code on the sentence from before. Don't worry if the parse tree does not make sense right now, since the model has not been trained yet. You should get the following tree and score:\n",
        "\n",
        "`tree:  (S|<ADJP> (S|<ADJP> (S|<ADJP> (DT The)) (S|<ADJP> (S|<ADJP> (NN boy)) (S|<ADJP> (S|<ADJP> (VBZ ate)) (S|<ADJP> (DT a))))) (S|<ADJP> (NN pie)))`\n",
        "\n",
        "`score:  1.4991785287857056`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-rhzOod0rrxc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhzOod0rrxc",
        "outputId": "d556101d-f7cb-4ca7-f9c2-329a8be57cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tree:  (S|<ADJP> (S|<ADJP> (S|<ADJP> (DT The)) (S|<ADJP> (S|<ADJP> (NN boy)) (S|<ADJP> (S|<ADJP> (VBZ ate)) (S|<ADJP> (DT a))))) (S|<ADJP> (NN pie)))\n",
            "score:  1.4991785287857056\n"
          ]
        }
      ],
      "source": [
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "tree, score =  parse(sentence)\n",
        "print(\"tree: \", tree.convert().linearize())\n",
        "print(\"score: \", score.value())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "03e04c2e",
      "metadata": {
        "id": "03e04c2e"
      },
      "source": [
        "## 2.3 Training the model\n",
        "\n",
        "Now we can train our model on the training data. Your first task is to implement a method that calculates the loss for a predicted parse tree given a sentence.\n",
        "\n",
        "Do this by first calculating the score and predicted parse tree, then calulating the score of a given gold parse tree.\n",
        "\n",
        "You should implement hinge loss where the loss is 0 if the predicted tree was correct and otherwise the difference between the score of the predicted tree and that of the reference tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c088e03",
      "metadata": {
        "id": "0c088e03"
      },
      "outputs": [],
      "source": [
        "def hinge_loss(sentence, gold_tree):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold_tree: gold reference parse tree for the sentence\n",
        "        \n",
        "    returns:\n",
        "        dynet expression containing the loss, i.e. dy.zeros(1) if correct and \n",
        "        difference between parse and oracle score if incorrect.\n",
        "    \"\"\"\n",
        "    \n",
        "    p_tree, p_score = parse(sentence,gold=gold_tree,force_gold = False)\n",
        "    g_tree, g_score = parse(sentence, gold=gold_tree, force_gold=True)\n",
        "\n",
        "    pred_tree = p_tree.convert().linearize()\n",
        "    tree = g_tree.convert().linearize()\n",
        "\n",
        "    if pred_tree == tree:\n",
        "        loss = dy.zeros(1)\n",
        "    else:\n",
        "      loss = p_score-g_score\n",
        "        \n",
        "    return loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "09847de5",
      "metadata": {
        "id": "09847de5"
      },
      "source": [
        "Now run training for 10 epochs, reporting the batch loss for each batch.\n",
        "\n",
        "You should iterate through the trees, extract the input sentence from the tree and generate the loss for each of them using the loss function defined above. Then add the loss to the `batch_losses` list and increase the `total_processed` counter at every sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca5b938",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dca5b938",
        "outputId": "f473eee9-1f0b-4667-e586-b310d2fa09f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 batch 1/89 processed 10 batch-loss 34.8215 epoch-elapsed 0h00m02s total-elapsed 0h00m02s\n",
            "epoch 0 batch 2/89 processed 20 batch-loss 37.5980 epoch-elapsed 0h00m05s total-elapsed 0h00m05s\n",
            "epoch 0 batch 3/89 processed 30 batch-loss 31.1126 epoch-elapsed 0h00m07s total-elapsed 0h00m07s\n",
            "epoch 0 batch 4/89 processed 40 batch-loss 38.9504 epoch-elapsed 0h00m10s total-elapsed 0h00m10s\n",
            "epoch 0 batch 5/89 processed 50 batch-loss 34.9492 epoch-elapsed 0h00m13s total-elapsed 0h00m13s\n",
            "epoch 0 batch 6/89 processed 60 batch-loss 45.1657 epoch-elapsed 0h00m17s total-elapsed 0h00m17s\n",
            "epoch 0 batch 7/89 processed 70 batch-loss 32.1836 epoch-elapsed 0h00m19s total-elapsed 0h00m19s\n",
            "epoch 0 batch 8/89 processed 80 batch-loss 32.6330 epoch-elapsed 0h00m22s total-elapsed 0h00m22s\n",
            "epoch 0 batch 9/89 processed 90 batch-loss 33.2372 epoch-elapsed 0h00m25s total-elapsed 0h00m25s\n",
            "epoch 0 batch 10/89 processed 100 batch-loss 35.8003 epoch-elapsed 0h00m27s total-elapsed 0h00m27s\n",
            "epoch 0 batch 11/89 processed 110 batch-loss 32.8355 epoch-elapsed 0h00m30s total-elapsed 0h00m30s\n",
            "epoch 0 batch 12/89 processed 120 batch-loss 34.5752 epoch-elapsed 0h00m33s total-elapsed 0h00m33s\n",
            "epoch 0 batch 13/89 processed 130 batch-loss 38.0875 epoch-elapsed 0h00m36s total-elapsed 0h00m36s\n",
            "epoch 0 batch 14/89 processed 140 batch-loss 26.5989 epoch-elapsed 0h00m38s total-elapsed 0h00m38s\n",
            "epoch 0 batch 15/89 processed 150 batch-loss 35.1166 epoch-elapsed 0h00m40s total-elapsed 0h00m40s\n",
            "epoch 0 batch 16/89 processed 160 batch-loss 33.3548 epoch-elapsed 0h00m43s total-elapsed 0h00m43s\n",
            "epoch 0 batch 17/89 processed 170 batch-loss 33.0130 epoch-elapsed 0h00m46s total-elapsed 0h00m46s\n",
            "epoch 0 batch 18/89 processed 180 batch-loss 29.9977 epoch-elapsed 0h00m48s total-elapsed 0h00m48s\n",
            "epoch 0 batch 19/89 processed 190 batch-loss 22.3513 epoch-elapsed 0h00m50s total-elapsed 0h00m50s\n",
            "epoch 0 batch 20/89 processed 200 batch-loss 32.1887 epoch-elapsed 0h00m52s total-elapsed 0h00m52s\n",
            "epoch 0 batch 21/89 processed 210 batch-loss 41.4287 epoch-elapsed 0h00m56s total-elapsed 0h00m56s\n",
            "epoch 0 batch 22/89 processed 220 batch-loss 42.5338 epoch-elapsed 0h00m59s total-elapsed 0h00m59s\n",
            "epoch 0 batch 23/89 processed 230 batch-loss 25.5503 epoch-elapsed 0h01m01s total-elapsed 0h01m01s\n",
            "epoch 0 batch 24/89 processed 240 batch-loss 26.0172 epoch-elapsed 0h01m03s total-elapsed 0h01m03s\n",
            "epoch 0 batch 25/89 processed 250 batch-loss 33.6566 epoch-elapsed 0h01m06s total-elapsed 0h01m06s\n",
            "epoch 0 batch 26/89 processed 260 batch-loss 39.8567 epoch-elapsed 0h01m09s total-elapsed 0h01m09s\n",
            "epoch 0 batch 27/89 processed 270 batch-loss 28.9700 epoch-elapsed 0h01m11s total-elapsed 0h01m11s\n",
            "epoch 0 batch 28/89 processed 280 batch-loss 34.2228 epoch-elapsed 0h01m14s total-elapsed 0h01m14s\n",
            "epoch 0 batch 29/89 processed 290 batch-loss 38.9185 epoch-elapsed 0h01m18s total-elapsed 0h01m18s\n",
            "epoch 0 batch 30/89 processed 300 batch-loss 25.8621 epoch-elapsed 0h01m19s total-elapsed 0h01m20s\n",
            "epoch 0 batch 31/89 processed 310 batch-loss 33.0941 epoch-elapsed 0h01m22s total-elapsed 0h01m22s\n",
            "epoch 0 batch 32/89 processed 320 batch-loss 28.9269 epoch-elapsed 0h01m24s total-elapsed 0h01m24s\n",
            "epoch 0 batch 33/89 processed 330 batch-loss 40.3194 epoch-elapsed 0h01m28s total-elapsed 0h01m28s\n",
            "epoch 0 batch 34/89 processed 340 batch-loss 25.0666 epoch-elapsed 0h01m30s total-elapsed 0h01m30s\n",
            "epoch 0 batch 35/89 processed 350 batch-loss 27.9453 epoch-elapsed 0h01m32s total-elapsed 0h01m32s\n",
            "epoch 0 batch 36/89 processed 360 batch-loss 33.4068 epoch-elapsed 0h01m34s total-elapsed 0h01m34s\n",
            "epoch 0 batch 37/89 processed 370 batch-loss 38.5252 epoch-elapsed 0h01m38s total-elapsed 0h01m38s\n",
            "epoch 0 batch 38/89 processed 380 batch-loss 29.3482 epoch-elapsed 0h01m40s total-elapsed 0h01m40s\n",
            "epoch 0 batch 39/89 processed 390 batch-loss 32.4140 epoch-elapsed 0h01m43s total-elapsed 0h01m43s\n",
            "epoch 0 batch 40/89 processed 400 batch-loss 33.6910 epoch-elapsed 0h01m45s total-elapsed 0h01m45s\n",
            "epoch 0 batch 41/89 processed 410 batch-loss 37.3448 epoch-elapsed 0h01m48s total-elapsed 0h01m48s\n",
            "epoch 0 batch 42/89 processed 420 batch-loss 27.9209 epoch-elapsed 0h01m50s total-elapsed 0h01m50s\n",
            "epoch 0 batch 43/89 processed 430 batch-loss 23.8979 epoch-elapsed 0h01m52s total-elapsed 0h01m52s\n",
            "epoch 0 batch 44/89 processed 440 batch-loss 27.7010 epoch-elapsed 0h01m54s total-elapsed 0h01m54s\n",
            "epoch 0 batch 45/89 processed 450 batch-loss 32.8656 epoch-elapsed 0h01m57s total-elapsed 0h01m57s\n",
            "epoch 0 batch 46/89 processed 460 batch-loss 35.6141 epoch-elapsed 0h02m00s total-elapsed 0h02m00s\n",
            "epoch 0 batch 47/89 processed 470 batch-loss 41.8017 epoch-elapsed 0h02m03s total-elapsed 0h02m03s\n",
            "epoch 0 batch 48/89 processed 480 batch-loss 46.3181 epoch-elapsed 0h02m07s total-elapsed 0h02m07s\n",
            "epoch 0 batch 49/89 processed 490 batch-loss 43.4913 epoch-elapsed 0h02m12s total-elapsed 0h02m12s\n",
            "epoch 0 batch 50/89 processed 500 batch-loss 29.7806 epoch-elapsed 0h02m15s total-elapsed 0h02m15s\n",
            "epoch 0 batch 51/89 processed 510 batch-loss 36.8946 epoch-elapsed 0h02m18s total-elapsed 0h02m18s\n",
            "epoch 0 batch 52/89 processed 520 batch-loss 32.5850 epoch-elapsed 0h02m20s total-elapsed 0h02m20s\n",
            "epoch 0 batch 53/89 processed 530 batch-loss 45.8563 epoch-elapsed 0h02m25s total-elapsed 0h02m25s\n",
            "epoch 0 batch 54/89 processed 540 batch-loss 28.5657 epoch-elapsed 0h02m27s total-elapsed 0h02m27s\n",
            "epoch 0 batch 55/89 processed 550 batch-loss 28.7982 epoch-elapsed 0h02m30s total-elapsed 0h02m30s\n",
            "epoch 0 batch 56/89 processed 560 batch-loss 27.7322 epoch-elapsed 0h02m32s total-elapsed 0h02m32s\n",
            "epoch 0 batch 57/89 processed 570 batch-loss 21.8679 epoch-elapsed 0h02m34s total-elapsed 0h02m34s\n",
            "epoch 0 batch 58/89 processed 580 batch-loss 29.5800 epoch-elapsed 0h02m36s total-elapsed 0h02m36s\n",
            "epoch 0 batch 59/89 processed 590 batch-loss 35.9727 epoch-elapsed 0h02m39s total-elapsed 0h02m39s\n",
            "epoch 0 batch 60/89 processed 600 batch-loss 31.3974 epoch-elapsed 0h02m42s total-elapsed 0h02m42s\n",
            "epoch 0 batch 61/89 processed 610 batch-loss 36.5270 epoch-elapsed 0h02m45s total-elapsed 0h02m45s\n",
            "epoch 0 batch 62/89 processed 620 batch-loss 28.3715 epoch-elapsed 0h02m47s total-elapsed 0h02m47s\n",
            "epoch 0 batch 63/89 processed 630 batch-loss 29.7778 epoch-elapsed 0h02m51s total-elapsed 0h02m51s\n",
            "epoch 0 batch 64/89 processed 640 batch-loss 29.5551 epoch-elapsed 0h02m53s total-elapsed 0h02m53s\n",
            "epoch 0 batch 65/89 processed 650 batch-loss 25.2649 epoch-elapsed 0h02m55s total-elapsed 0h02m55s\n",
            "epoch 0 batch 66/89 processed 660 batch-loss 38.1324 epoch-elapsed 0h02m58s total-elapsed 0h02m58s\n",
            "epoch 0 batch 67/89 processed 670 batch-loss 33.9400 epoch-elapsed 0h03m02s total-elapsed 0h03m02s\n",
            "epoch 0 batch 68/89 processed 680 batch-loss 27.8557 epoch-elapsed 0h03m04s total-elapsed 0h03m04s\n",
            "epoch 0 batch 69/89 processed 690 batch-loss 33.8806 epoch-elapsed 0h03m07s total-elapsed 0h03m07s\n",
            "epoch 0 batch 70/89 processed 700 batch-loss 27.8946 epoch-elapsed 0h03m09s total-elapsed 0h03m09s\n",
            "epoch 0 batch 71/89 processed 710 batch-loss 30.1928 epoch-elapsed 0h03m12s total-elapsed 0h03m12s\n",
            "epoch 0 batch 72/89 processed 720 batch-loss 38.0782 epoch-elapsed 0h03m15s total-elapsed 0h03m15s\n",
            "epoch 0 batch 73/89 processed 730 batch-loss 37.8692 epoch-elapsed 0h03m19s total-elapsed 0h03m19s\n",
            "epoch 0 batch 74/89 processed 740 batch-loss 36.6442 epoch-elapsed 0h03m22s total-elapsed 0h03m22s\n",
            "epoch 0 batch 75/89 processed 750 batch-loss 27.3171 epoch-elapsed 0h03m24s total-elapsed 0h03m24s\n",
            "epoch 0 batch 76/89 processed 760 batch-loss 34.1379 epoch-elapsed 0h03m27s total-elapsed 0h03m27s\n",
            "epoch 0 batch 77/89 processed 770 batch-loss 30.4991 epoch-elapsed 0h03m29s total-elapsed 0h03m29s\n",
            "epoch 0 batch 78/89 processed 780 batch-loss 34.4247 epoch-elapsed 0h03m32s total-elapsed 0h03m32s\n",
            "epoch 0 batch 79/89 processed 790 batch-loss 33.4337 epoch-elapsed 0h03m35s total-elapsed 0h03m35s\n",
            "epoch 0 batch 80/89 processed 800 batch-loss 28.4743 epoch-elapsed 0h03m37s total-elapsed 0h03m37s\n",
            "epoch 0 batch 81/89 processed 810 batch-loss 27.9466 epoch-elapsed 0h03m39s total-elapsed 0h03m39s\n",
            "epoch 0 batch 82/89 processed 820 batch-loss 27.6668 epoch-elapsed 0h03m42s total-elapsed 0h03m42s\n",
            "epoch 0 batch 83/89 processed 830 batch-loss 31.3674 epoch-elapsed 0h03m44s total-elapsed 0h03m44s\n",
            "epoch 0 batch 84/89 processed 840 batch-loss 38.6770 epoch-elapsed 0h03m48s total-elapsed 0h03m48s\n",
            "epoch 0 batch 85/89 processed 850 batch-loss 36.0521 epoch-elapsed 0h03m52s total-elapsed 0h03m52s\n",
            "epoch 0 batch 86/89 processed 860 batch-loss 28.1409 epoch-elapsed 0h03m54s total-elapsed 0h03m54s\n",
            "epoch 0 batch 87/89 processed 870 batch-loss 37.4291 epoch-elapsed 0h03m57s total-elapsed 0h03m57s\n",
            "epoch 0 batch 88/89 processed 880 batch-loss 38.2536 epoch-elapsed 0h04m01s total-elapsed 0h04m01s\n",
            "epoch 0 batch 89/89 processed 886 batch-loss 30.3514 epoch-elapsed 0h04m02s total-elapsed 0h04m02s\n",
            "epoch 1 batch 1/89 processed 896 batch-loss 28.3531 epoch-elapsed 0h00m02s total-elapsed 0h04m05s\n",
            "epoch 1 batch 2/89 processed 906 batch-loss 23.6875 epoch-elapsed 0h00m04s total-elapsed 0h04m07s\n",
            "epoch 1 batch 3/89 processed 916 batch-loss 27.5320 epoch-elapsed 0h00m06s total-elapsed 0h04m09s\n",
            "epoch 1 batch 4/89 processed 926 batch-loss 38.1222 epoch-elapsed 0h00m10s total-elapsed 0h04m12s\n",
            "epoch 1 batch 5/89 processed 936 batch-loss 36.2564 epoch-elapsed 0h00m13s total-elapsed 0h04m15s\n",
            "epoch 1 batch 6/89 processed 946 batch-loss 29.0629 epoch-elapsed 0h00m15s total-elapsed 0h04m18s\n",
            "epoch 1 batch 7/89 processed 956 batch-loss 40.4224 epoch-elapsed 0h00m19s total-elapsed 0h04m22s\n",
            "epoch 1 batch 8/89 processed 966 batch-loss 35.4447 epoch-elapsed 0h00m22s total-elapsed 0h04m25s\n",
            "epoch 1 batch 9/89 processed 976 batch-loss 24.2860 epoch-elapsed 0h00m24s total-elapsed 0h04m27s\n",
            "epoch 1 batch 10/89 processed 986 batch-loss 33.1677 epoch-elapsed 0h00m27s total-elapsed 0h04m30s\n",
            "epoch 1 batch 11/89 processed 996 batch-loss 31.1131 epoch-elapsed 0h00m30s total-elapsed 0h04m32s\n",
            "epoch 1 batch 12/89 processed 1,006 batch-loss 33.7997 epoch-elapsed 0h00m32s total-elapsed 0h04m35s\n",
            "epoch 1 batch 13/89 processed 1,016 batch-loss 22.0868 epoch-elapsed 0h00m34s total-elapsed 0h04m37s\n",
            "epoch 1 batch 14/89 processed 1,026 batch-loss 30.8234 epoch-elapsed 0h00m37s total-elapsed 0h04m39s\n",
            "epoch 1 batch 15/89 processed 1,036 batch-loss 39.3584 epoch-elapsed 0h00m41s total-elapsed 0h04m43s\n",
            "epoch 1 batch 16/89 processed 1,046 batch-loss 34.7420 epoch-elapsed 0h00m44s total-elapsed 0h04m46s\n",
            "epoch 1 batch 17/89 processed 1,056 batch-loss 30.6827 epoch-elapsed 0h00m46s total-elapsed 0h04m49s\n",
            "epoch 1 batch 18/89 processed 1,066 batch-loss 27.7362 epoch-elapsed 0h00m48s total-elapsed 0h04m51s\n",
            "epoch 1 batch 19/89 processed 1,076 batch-loss 35.2677 epoch-elapsed 0h00m51s total-elapsed 0h04m54s\n",
            "epoch 1 batch 20/89 processed 1,086 batch-loss 24.2020 epoch-elapsed 0h00m53s total-elapsed 0h04m56s\n",
            "epoch 1 batch 21/89 processed 1,096 batch-loss 29.5996 epoch-elapsed 0h00m56s total-elapsed 0h04m58s\n",
            "epoch 1 batch 22/89 processed 1,106 batch-loss 36.7273 epoch-elapsed 0h00m59s total-elapsed 0h05m02s\n",
            "epoch 1 batch 23/89 processed 1,116 batch-loss 36.5625 epoch-elapsed 0h01m02s total-elapsed 0h05m05s\n",
            "epoch 1 batch 24/89 processed 1,126 batch-loss 36.9106 epoch-elapsed 0h01m05s total-elapsed 0h05m08s\n",
            "epoch 1 batch 25/89 processed 1,136 batch-loss 32.7663 epoch-elapsed 0h01m08s total-elapsed 0h05m11s\n",
            "epoch 1 batch 26/89 processed 1,146 batch-loss 30.2574 epoch-elapsed 0h01m11s total-elapsed 0h05m13s\n",
            "epoch 1 batch 27/89 processed 1,156 batch-loss 27.0804 epoch-elapsed 0h01m13s total-elapsed 0h05m16s\n",
            "epoch 1 batch 28/89 processed 1,166 batch-loss 32.3262 epoch-elapsed 0h01m16s total-elapsed 0h05m19s\n",
            "epoch 1 batch 29/89 processed 1,176 batch-loss 27.2883 epoch-elapsed 0h01m18s total-elapsed 0h05m21s\n",
            "epoch 1 batch 30/89 processed 1,186 batch-loss 29.2585 epoch-elapsed 0h01m21s total-elapsed 0h05m23s\n",
            "epoch 1 batch 31/89 processed 1,196 batch-loss 32.9505 epoch-elapsed 0h01m23s total-elapsed 0h05m26s\n",
            "epoch 1 batch 32/89 processed 1,206 batch-loss 26.1939 epoch-elapsed 0h01m26s total-elapsed 0h05m28s\n",
            "epoch 1 batch 33/89 processed 1,216 batch-loss 32.5636 epoch-elapsed 0h01m29s total-elapsed 0h05m31s\n",
            "epoch 1 batch 34/89 processed 1,226 batch-loss 41.8549 epoch-elapsed 0h01m32s total-elapsed 0h05m35s\n",
            "epoch 1 batch 35/89 processed 1,236 batch-loss 24.6310 epoch-elapsed 0h01m34s total-elapsed 0h05m37s\n",
            "epoch 1 batch 36/89 processed 1,246 batch-loss 30.4447 epoch-elapsed 0h01m37s total-elapsed 0h05m40s\n",
            "epoch 1 batch 37/89 processed 1,256 batch-loss 34.1771 epoch-elapsed 0h01m40s total-elapsed 0h05m42s\n",
            "epoch 1 batch 38/89 processed 1,266 batch-loss 25.1562 epoch-elapsed 0h01m42s total-elapsed 0h05m45s\n",
            "epoch 1 batch 39/89 processed 1,276 batch-loss 27.9707 epoch-elapsed 0h01m44s total-elapsed 0h05m47s\n",
            "epoch 1 batch 40/89 processed 1,286 batch-loss 28.8859 epoch-elapsed 0h01m47s total-elapsed 0h05m49s\n",
            "epoch 1 batch 41/89 processed 1,296 batch-loss 25.6060 epoch-elapsed 0h01m49s total-elapsed 0h05m51s\n",
            "epoch 1 batch 42/89 processed 1,306 batch-loss 25.0948 epoch-elapsed 0h01m51s total-elapsed 0h05m53s\n",
            "epoch 1 batch 43/89 processed 1,316 batch-loss 28.4981 epoch-elapsed 0h01m53s total-elapsed 0h05m56s\n",
            "epoch 1 batch 44/89 processed 1,326 batch-loss 32.7133 epoch-elapsed 0h01m56s total-elapsed 0h05m59s\n",
            "epoch 1 batch 45/89 processed 1,336 batch-loss 31.5692 epoch-elapsed 0h01m59s total-elapsed 0h06m02s\n",
            "epoch 1 batch 46/89 processed 1,346 batch-loss 20.1075 epoch-elapsed 0h02m00s total-elapsed 0h06m03s\n",
            "epoch 1 batch 47/89 processed 1,356 batch-loss 41.2113 epoch-elapsed 0h02m04s total-elapsed 0h06m07s\n",
            "epoch 1 batch 48/89 processed 1,366 batch-loss 38.9688 epoch-elapsed 0h02m08s total-elapsed 0h06m11s\n",
            "epoch 1 batch 49/89 processed 1,376 batch-loss 27.0308 epoch-elapsed 0h02m11s total-elapsed 0h06m14s\n",
            "epoch 1 batch 50/89 processed 1,386 batch-loss 26.9650 epoch-elapsed 0h02m14s total-elapsed 0h06m16s\n",
            "epoch 1 batch 51/89 processed 1,396 batch-loss 31.8289 epoch-elapsed 0h02m16s total-elapsed 0h06m19s\n",
            "epoch 1 batch 52/89 processed 1,406 batch-loss 29.7052 epoch-elapsed 0h02m19s total-elapsed 0h06m21s\n",
            "epoch 1 batch 53/89 processed 1,416 batch-loss 22.4896 epoch-elapsed 0h02m21s total-elapsed 0h06m24s\n",
            "epoch 1 batch 54/89 processed 1,426 batch-loss 25.4334 epoch-elapsed 0h02m23s total-elapsed 0h06m26s\n",
            "epoch 1 batch 55/89 processed 1,436 batch-loss 23.8819 epoch-elapsed 0h02m25s total-elapsed 0h06m28s\n",
            "epoch 1 batch 56/89 processed 1,446 batch-loss 34.2846 epoch-elapsed 0h02m28s total-elapsed 0h06m31s\n",
            "epoch 1 batch 57/89 processed 1,456 batch-loss 28.8691 epoch-elapsed 0h02m31s total-elapsed 0h06m33s\n",
            "epoch 1 batch 58/89 processed 1,466 batch-loss 33.7530 epoch-elapsed 0h02m34s total-elapsed 0h06m36s\n",
            "epoch 1 batch 59/89 processed 1,476 batch-loss 31.7307 epoch-elapsed 0h02m37s total-elapsed 0h06m39s\n",
            "epoch 1 batch 60/89 processed 1,486 batch-loss 34.5203 epoch-elapsed 0h02m40s total-elapsed 0h06m42s\n",
            "epoch 1 batch 61/89 processed 1,496 batch-loss 29.4876 epoch-elapsed 0h02m42s total-elapsed 0h06m45s\n",
            "epoch 1 batch 62/89 processed 1,506 batch-loss 36.0102 epoch-elapsed 0h02m46s total-elapsed 0h06m48s\n",
            "epoch 1 batch 63/89 processed 1,516 batch-loss 31.0829 epoch-elapsed 0h02m48s total-elapsed 0h06m51s\n",
            "epoch 1 batch 64/89 processed 1,526 batch-loss 30.1223 epoch-elapsed 0h02m51s total-elapsed 0h06m53s\n",
            "epoch 1 batch 65/89 processed 1,536 batch-loss 35.8657 epoch-elapsed 0h02m54s total-elapsed 0h06m56s\n",
            "epoch 1 batch 66/89 processed 1,546 batch-loss 34.3175 epoch-elapsed 0h02m57s total-elapsed 0h07m00s\n",
            "epoch 1 batch 67/89 processed 1,556 batch-loss 37.6988 epoch-elapsed 0h03m01s total-elapsed 0h07m03s\n",
            "epoch 1 batch 68/89 processed 1,566 batch-loss 34.5688 epoch-elapsed 0h03m04s total-elapsed 0h07m06s\n",
            "epoch 1 batch 69/89 processed 1,576 batch-loss 25.9940 epoch-elapsed 0h03m06s total-elapsed 0h07m09s\n",
            "epoch 1 batch 70/89 processed 1,586 batch-loss 47.1415 epoch-elapsed 0h03m11s total-elapsed 0h07m13s\n",
            "epoch 1 batch 71/89 processed 1,596 batch-loss 36.2122 epoch-elapsed 0h03m14s total-elapsed 0h07m17s\n",
            "epoch 1 batch 72/89 processed 1,606 batch-loss 31.0482 epoch-elapsed 0h03m17s total-elapsed 0h07m19s\n",
            "epoch 1 batch 73/89 processed 1,616 batch-loss 28.6312 epoch-elapsed 0h03m19s total-elapsed 0h07m22s\n",
            "epoch 1 batch 74/89 processed 1,626 batch-loss 33.1761 epoch-elapsed 0h03m22s total-elapsed 0h07m25s\n",
            "epoch 1 batch 75/89 processed 1,636 batch-loss 27.0543 epoch-elapsed 0h03m25s total-elapsed 0h07m27s\n",
            "epoch 1 batch 76/89 processed 1,646 batch-loss 27.4107 epoch-elapsed 0h03m27s total-elapsed 0h07m30s\n",
            "epoch 1 batch 77/89 processed 1,656 batch-loss 22.7225 epoch-elapsed 0h03m29s total-elapsed 0h07m32s\n",
            "epoch 1 batch 78/89 processed 1,666 batch-loss 35.6791 epoch-elapsed 0h03m32s total-elapsed 0h07m35s\n",
            "epoch 1 batch 79/89 processed 1,676 batch-loss 17.7986 epoch-elapsed 0h03m34s total-elapsed 0h07m36s\n",
            "epoch 1 batch 80/89 processed 1,686 batch-loss 28.1459 epoch-elapsed 0h03m36s total-elapsed 0h07m39s\n",
            "epoch 1 batch 81/89 processed 1,696 batch-loss 22.7714 epoch-elapsed 0h03m38s total-elapsed 0h07m41s\n",
            "epoch 1 batch 82/89 processed 1,706 batch-loss 32.0539 epoch-elapsed 0h03m41s total-elapsed 0h07m44s\n",
            "epoch 1 batch 83/89 processed 1,716 batch-loss 31.6728 epoch-elapsed 0h03m44s total-elapsed 0h07m47s\n",
            "epoch 1 batch 84/89 processed 1,726 batch-loss 31.7643 epoch-elapsed 0h03m47s total-elapsed 0h07m49s\n",
            "epoch 1 batch 85/89 processed 1,736 batch-loss 33.4645 epoch-elapsed 0h03m50s total-elapsed 0h07m52s\n",
            "epoch 1 batch 86/89 processed 1,746 batch-loss 29.5619 epoch-elapsed 0h03m52s total-elapsed 0h07m55s\n",
            "epoch 1 batch 87/89 processed 1,756 batch-loss 31.8604 epoch-elapsed 0h03m56s total-elapsed 0h07m58s\n",
            "epoch 1 batch 88/89 processed 1,766 batch-loss 40.7166 epoch-elapsed 0h04m00s total-elapsed 0h08m02s\n",
            "epoch 1 batch 89/89 processed 1,772 batch-loss 27.2704 epoch-elapsed 0h04m01s total-elapsed 0h08m04s\n",
            "epoch 2 batch 1/89 processed 1,782 batch-loss 27.6352 epoch-elapsed 0h00m02s total-elapsed 0h08m06s\n",
            "epoch 2 batch 2/89 processed 1,792 batch-loss 33.9557 epoch-elapsed 0h00m05s total-elapsed 0h08m09s\n",
            "epoch 2 batch 3/89 processed 1,802 batch-loss 28.8856 epoch-elapsed 0h00m08s total-elapsed 0h08m12s\n",
            "epoch 2 batch 4/89 processed 1,812 batch-loss 26.9765 epoch-elapsed 0h00m10s total-elapsed 0h08m14s\n",
            "epoch 2 batch 5/89 processed 1,822 batch-loss 20.2230 epoch-elapsed 0h00m12s total-elapsed 0h08m16s\n",
            "epoch 2 batch 6/89 processed 1,832 batch-loss 21.5755 epoch-elapsed 0h00m14s total-elapsed 0h08m18s\n",
            "epoch 2 batch 7/89 processed 1,842 batch-loss 23.3145 epoch-elapsed 0h00m16s total-elapsed 0h08m20s\n",
            "epoch 2 batch 8/89 processed 1,852 batch-loss 28.4618 epoch-elapsed 0h00m19s total-elapsed 0h08m23s\n",
            "epoch 2 batch 9/89 processed 1,862 batch-loss 29.5688 epoch-elapsed 0h00m21s total-elapsed 0h08m26s\n",
            "epoch 2 batch 10/89 processed 1,872 batch-loss 26.3260 epoch-elapsed 0h00m24s total-elapsed 0h08m28s\n",
            "epoch 2 batch 11/89 processed 1,882 batch-loss 25.0598 epoch-elapsed 0h00m26s total-elapsed 0h08m30s\n",
            "epoch 2 batch 12/89 processed 1,892 batch-loss 32.9946 epoch-elapsed 0h00m29s total-elapsed 0h08m33s\n",
            "epoch 2 batch 13/89 processed 1,902 batch-loss 34.0727 epoch-elapsed 0h00m32s total-elapsed 0h08m37s\n",
            "epoch 2 batch 14/89 processed 1,912 batch-loss 26.6421 epoch-elapsed 0h00m35s total-elapsed 0h08m39s\n",
            "epoch 2 batch 15/89 processed 1,922 batch-loss 32.3652 epoch-elapsed 0h00m38s total-elapsed 0h08m42s\n",
            "epoch 2 batch 16/89 processed 1,932 batch-loss 31.3287 epoch-elapsed 0h00m41s total-elapsed 0h08m45s\n",
            "epoch 2 batch 17/89 processed 1,942 batch-loss 30.3519 epoch-elapsed 0h00m44s total-elapsed 0h08m48s\n",
            "epoch 2 batch 18/89 processed 1,952 batch-loss 24.0447 epoch-elapsed 0h00m46s total-elapsed 0h08m51s\n",
            "epoch 2 batch 19/89 processed 1,962 batch-loss 41.3764 epoch-elapsed 0h00m51s total-elapsed 0h08m55s\n",
            "epoch 2 batch 20/89 processed 1,972 batch-loss 27.0241 epoch-elapsed 0h00m53s total-elapsed 0h08m57s\n",
            "epoch 2 batch 21/89 processed 1,982 batch-loss 31.8496 epoch-elapsed 0h00m56s total-elapsed 0h09m00s\n",
            "epoch 2 batch 22/89 processed 1,992 batch-loss 28.0548 epoch-elapsed 0h00m59s total-elapsed 0h09m03s\n",
            "epoch 2 batch 23/89 processed 2,002 batch-loss 28.8419 epoch-elapsed 0h01m01s total-elapsed 0h09m06s\n",
            "epoch 2 batch 24/89 processed 2,012 batch-loss 23.6393 epoch-elapsed 0h01m04s total-elapsed 0h09m08s\n",
            "epoch 2 batch 25/89 processed 2,022 batch-loss 36.3400 epoch-elapsed 0h01m08s total-elapsed 0h09m12s\n",
            "epoch 2 batch 26/89 processed 2,032 batch-loss 21.8883 epoch-elapsed 0h01m10s total-elapsed 0h09m14s\n",
            "epoch 2 batch 27/89 processed 2,042 batch-loss 26.5851 epoch-elapsed 0h01m13s total-elapsed 0h09m17s\n",
            "epoch 2 batch 28/89 processed 2,052 batch-loss 29.7765 epoch-elapsed 0h01m15s total-elapsed 0h09m20s\n",
            "epoch 2 batch 29/89 processed 2,062 batch-loss 32.3954 epoch-elapsed 0h01m18s total-elapsed 0h09m23s\n",
            "epoch 2 batch 30/89 processed 2,072 batch-loss 26.7649 epoch-elapsed 0h01m21s total-elapsed 0h09m25s\n",
            "epoch 2 batch 31/89 processed 2,082 batch-loss 22.2513 epoch-elapsed 0h01m23s total-elapsed 0h09m28s\n",
            "epoch 2 batch 32/89 processed 2,092 batch-loss 26.3550 epoch-elapsed 0h01m26s total-elapsed 0h09m30s\n",
            "epoch 2 batch 33/89 processed 2,102 batch-loss 24.4052 epoch-elapsed 0h01m29s total-elapsed 0h09m33s\n",
            "epoch 2 batch 34/89 processed 2,112 batch-loss 26.7975 epoch-elapsed 0h01m32s total-elapsed 0h09m37s\n",
            "epoch 2 batch 35/89 processed 2,122 batch-loss 25.0209 epoch-elapsed 0h01m35s total-elapsed 0h09m39s\n",
            "epoch 2 batch 36/89 processed 2,132 batch-loss 30.5051 epoch-elapsed 0h01m38s total-elapsed 0h09m42s\n",
            "epoch 2 batch 37/89 processed 2,142 batch-loss 32.7596 epoch-elapsed 0h01m42s total-elapsed 0h09m46s\n",
            "epoch 2 batch 38/89 processed 2,152 batch-loss 29.3235 epoch-elapsed 0h01m45s total-elapsed 0h09m49s\n",
            "epoch 2 batch 39/89 processed 2,162 batch-loss 28.0482 epoch-elapsed 0h01m48s total-elapsed 0h09m52s\n",
            "epoch 2 batch 40/89 processed 2,172 batch-loss 27.0681 epoch-elapsed 0h01m51s total-elapsed 0h09m55s\n",
            "epoch 2 batch 41/89 processed 2,182 batch-loss 27.5096 epoch-elapsed 0h01m54s total-elapsed 0h09m58s\n",
            "epoch 2 batch 42/89 processed 2,192 batch-loss 19.5307 epoch-elapsed 0h01m56s total-elapsed 0h10m00s\n",
            "epoch 2 batch 43/89 processed 2,202 batch-loss 26.6564 epoch-elapsed 0h01m59s total-elapsed 0h10m03s\n",
            "epoch 2 batch 44/89 processed 2,212 batch-loss 22.6375 epoch-elapsed 0h02m01s total-elapsed 0h10m06s\n",
            "epoch 2 batch 45/89 processed 2,222 batch-loss 29.0550 epoch-elapsed 0h02m05s total-elapsed 0h10m09s\n",
            "epoch 2 batch 46/89 processed 2,232 batch-loss 28.4956 epoch-elapsed 0h02m08s total-elapsed 0h10m12s\n",
            "epoch 2 batch 47/89 processed 2,242 batch-loss 25.3650 epoch-elapsed 0h02m11s total-elapsed 0h10m15s\n",
            "epoch 2 batch 48/89 processed 2,252 batch-loss 13.9079 epoch-elapsed 0h02m13s total-elapsed 0h10m17s\n",
            "epoch 2 batch 49/89 processed 2,262 batch-loss 25.8635 epoch-elapsed 0h02m16s total-elapsed 0h10m20s\n",
            "epoch 2 batch 50/89 processed 2,272 batch-loss 19.8918 epoch-elapsed 0h02m18s total-elapsed 0h10m22s\n",
            "epoch 2 batch 51/89 processed 2,282 batch-loss 15.6289 epoch-elapsed 0h02m20s total-elapsed 0h10m24s\n",
            "epoch 2 batch 52/89 processed 2,292 batch-loss 25.8928 epoch-elapsed 0h02m23s total-elapsed 0h10m27s\n",
            "epoch 2 batch 53/89 processed 2,302 batch-loss 21.6592 epoch-elapsed 0h02m25s total-elapsed 0h10m29s\n",
            "epoch 2 batch 54/89 processed 2,312 batch-loss 18.6272 epoch-elapsed 0h02m27s total-elapsed 0h10m32s\n",
            "epoch 2 batch 55/89 processed 2,322 batch-loss 24.0737 epoch-elapsed 0h02m30s total-elapsed 0h10m34s\n",
            "epoch 2 batch 56/89 processed 2,332 batch-loss 22.6502 epoch-elapsed 0h02m33s total-elapsed 0h10m37s\n",
            "epoch 2 batch 57/89 processed 2,342 batch-loss 26.8563 epoch-elapsed 0h02m36s total-elapsed 0h10m40s\n",
            "epoch 2 batch 58/89 processed 2,352 batch-loss 20.6383 epoch-elapsed 0h02m38s total-elapsed 0h10m42s\n",
            "epoch 2 batch 59/89 processed 2,362 batch-loss 25.3413 epoch-elapsed 0h02m41s total-elapsed 0h10m45s\n",
            "epoch 2 batch 60/89 processed 2,372 batch-loss 19.9198 epoch-elapsed 0h02m43s total-elapsed 0h10m48s\n",
            "epoch 2 batch 61/89 processed 2,382 batch-loss 23.9380 epoch-elapsed 0h02m46s total-elapsed 0h10m50s\n",
            "epoch 2 batch 62/89 processed 2,392 batch-loss 19.8559 epoch-elapsed 0h02m49s total-elapsed 0h10m53s\n",
            "epoch 2 batch 63/89 processed 2,402 batch-loss 22.5062 epoch-elapsed 0h02m51s total-elapsed 0h10m56s\n",
            "epoch 2 batch 64/89 processed 2,412 batch-loss 16.1297 epoch-elapsed 0h02m53s total-elapsed 0h10m57s\n",
            "epoch 2 batch 65/89 processed 2,422 batch-loss 33.5012 epoch-elapsed 0h02m57s total-elapsed 0h11m01s\n",
            "epoch 2 batch 66/89 processed 2,432 batch-loss 16.7765 epoch-elapsed 0h02m59s total-elapsed 0h11m03s\n",
            "epoch 2 batch 67/89 processed 2,442 batch-loss 25.4529 epoch-elapsed 0h03m02s total-elapsed 0h11m06s\n",
            "epoch 2 batch 68/89 processed 2,452 batch-loss 22.6985 epoch-elapsed 0h03m05s total-elapsed 0h11m09s\n",
            "epoch 2 batch 69/89 processed 2,462 batch-loss 19.0767 epoch-elapsed 0h03m07s total-elapsed 0h11m11s\n",
            "epoch 2 batch 70/89 processed 2,472 batch-loss 22.3612 epoch-elapsed 0h03m10s total-elapsed 0h11m14s\n",
            "epoch 2 batch 71/89 processed 2,482 batch-loss 18.8831 epoch-elapsed 0h03m12s total-elapsed 0h11m17s\n",
            "epoch 2 batch 72/89 processed 2,492 batch-loss 18.8255 epoch-elapsed 0h03m15s total-elapsed 0h11m19s\n",
            "epoch 2 batch 73/89 processed 2,502 batch-loss 26.4876 epoch-elapsed 0h03m18s total-elapsed 0h11m22s\n",
            "epoch 2 batch 74/89 processed 2,512 batch-loss 20.7930 epoch-elapsed 0h03m20s total-elapsed 0h11m25s\n",
            "epoch 2 batch 75/89 processed 2,522 batch-loss 31.2266 epoch-elapsed 0h03m24s total-elapsed 0h11m28s\n",
            "epoch 2 batch 76/89 processed 2,532 batch-loss 16.9124 epoch-elapsed 0h03m26s total-elapsed 0h11m31s\n",
            "epoch 2 batch 77/89 processed 2,542 batch-loss 21.5951 epoch-elapsed 0h03m29s total-elapsed 0h11m34s\n",
            "epoch 2 batch 78/89 processed 2,552 batch-loss 14.1730 epoch-elapsed 0h03m31s total-elapsed 0h11m35s\n",
            "epoch 2 batch 79/89 processed 2,562 batch-loss 23.6428 epoch-elapsed 0h03m34s total-elapsed 0h11m38s\n",
            "epoch 2 batch 80/89 processed 2,572 batch-loss 17.9581 epoch-elapsed 0h03m36s total-elapsed 0h11m40s\n",
            "epoch 2 batch 81/89 processed 2,582 batch-loss 21.5969 epoch-elapsed 0h03m39s total-elapsed 0h11m43s\n",
            "epoch 2 batch 82/89 processed 2,592 batch-loss 20.5897 epoch-elapsed 0h03m41s total-elapsed 0h11m45s\n",
            "epoch 2 batch 83/89 processed 2,602 batch-loss 26.8548 epoch-elapsed 0h03m45s total-elapsed 0h11m49s\n",
            "epoch 2 batch 84/89 processed 2,612 batch-loss 23.4680 epoch-elapsed 0h03m48s total-elapsed 0h11m52s\n",
            "epoch 2 batch 85/89 processed 2,622 batch-loss 20.0432 epoch-elapsed 0h03m50s total-elapsed 0h11m55s\n",
            "epoch 2 batch 86/89 processed 2,632 batch-loss 19.2633 epoch-elapsed 0h03m53s total-elapsed 0h11m57s\n",
            "epoch 2 batch 87/89 processed 2,642 batch-loss 27.0071 epoch-elapsed 0h03m57s total-elapsed 0h12m01s\n",
            "epoch 2 batch 88/89 processed 2,652 batch-loss 19.2686 epoch-elapsed 0h03m59s total-elapsed 0h12m04s\n",
            "epoch 2 batch 89/89 processed 2,658 batch-loss 21.1181 epoch-elapsed 0h04m01s total-elapsed 0h12m05s\n",
            "epoch 3 batch 1/89 processed 2,668 batch-loss 22.0946 epoch-elapsed 0h00m02s total-elapsed 0h12m08s\n",
            "epoch 3 batch 2/89 processed 2,678 batch-loss 13.2456 epoch-elapsed 0h00m04s total-elapsed 0h12m10s\n",
            "epoch 3 batch 3/89 processed 2,688 batch-loss 21.7939 epoch-elapsed 0h00m07s total-elapsed 0h12m12s\n",
            "epoch 3 batch 4/89 processed 2,698 batch-loss 17.5284 epoch-elapsed 0h00m09s total-elapsed 0h12m15s\n",
            "epoch 3 batch 5/89 processed 2,708 batch-loss 24.5236 epoch-elapsed 0h00m12s total-elapsed 0h12m18s\n",
            "epoch 3 batch 6/89 processed 2,718 batch-loss 25.0329 epoch-elapsed 0h00m16s total-elapsed 0h12m22s\n",
            "epoch 3 batch 7/89 processed 2,728 batch-loss 20.8673 epoch-elapsed 0h00m19s total-elapsed 0h12m24s\n",
            "epoch 3 batch 8/89 processed 2,738 batch-loss 17.4471 epoch-elapsed 0h00m21s total-elapsed 0h12m27s\n",
            "epoch 3 batch 9/89 processed 2,748 batch-loss 18.6420 epoch-elapsed 0h00m23s total-elapsed 0h12m29s\n",
            "epoch 3 batch 10/89 processed 2,758 batch-loss 12.7737 epoch-elapsed 0h00m25s total-elapsed 0h12m31s\n",
            "epoch 3 batch 11/89 processed 2,768 batch-loss 20.6050 epoch-elapsed 0h00m28s total-elapsed 0h12m34s\n",
            "epoch 3 batch 12/89 processed 2,778 batch-loss 16.8024 epoch-elapsed 0h00m31s total-elapsed 0h12m37s\n",
            "epoch 3 batch 13/89 processed 2,788 batch-loss 20.0594 epoch-elapsed 0h00m34s total-elapsed 0h12m40s\n",
            "epoch 3 batch 14/89 processed 2,798 batch-loss 17.9042 epoch-elapsed 0h00m36s total-elapsed 0h12m42s\n",
            "epoch 3 batch 15/89 processed 2,808 batch-loss 14.6963 epoch-elapsed 0h00m38s total-elapsed 0h12m44s\n",
            "epoch 3 batch 16/89 processed 2,818 batch-loss 17.8151 epoch-elapsed 0h00m41s total-elapsed 0h12m47s\n",
            "epoch 3 batch 17/89 processed 2,828 batch-loss 16.9308 epoch-elapsed 0h00m43s total-elapsed 0h12m49s\n",
            "epoch 3 batch 18/89 processed 2,838 batch-loss 22.7319 epoch-elapsed 0h00m47s total-elapsed 0h12m52s\n",
            "epoch 3 batch 19/89 processed 2,848 batch-loss 18.2133 epoch-elapsed 0h00m49s total-elapsed 0h12m55s\n",
            "epoch 3 batch 20/89 processed 2,858 batch-loss 20.6186 epoch-elapsed 0h00m54s total-elapsed 0h13m00s\n",
            "epoch 3 batch 21/89 processed 2,868 batch-loss 10.6276 epoch-elapsed 0h00m56s total-elapsed 0h13m01s\n",
            "epoch 3 batch 22/89 processed 2,878 batch-loss 19.8805 epoch-elapsed 0h00m59s total-elapsed 0h13m05s\n",
            "epoch 3 batch 23/89 processed 2,888 batch-loss 14.2008 epoch-elapsed 0h01m01s total-elapsed 0h13m07s\n",
            "epoch 3 batch 24/89 processed 2,898 batch-loss 21.5820 epoch-elapsed 0h01m04s total-elapsed 0h13m10s\n",
            "epoch 3 batch 25/89 processed 2,908 batch-loss 26.1068 epoch-elapsed 0h01m08s total-elapsed 0h13m14s\n",
            "epoch 3 batch 26/89 processed 2,918 batch-loss 19.0349 epoch-elapsed 0h01m11s total-elapsed 0h13m17s\n",
            "epoch 3 batch 27/89 processed 2,928 batch-loss 15.9994 epoch-elapsed 0h01m14s total-elapsed 0h13m19s\n",
            "epoch 3 batch 28/89 processed 2,938 batch-loss 11.3641 epoch-elapsed 0h01m15s total-elapsed 0h13m21s\n",
            "epoch 3 batch 29/89 processed 2,948 batch-loss 15.9138 epoch-elapsed 0h01m18s total-elapsed 0h13m24s\n",
            "epoch 3 batch 30/89 processed 2,958 batch-loss 18.0987 epoch-elapsed 0h01m21s total-elapsed 0h13m26s\n",
            "epoch 3 batch 31/89 processed 2,968 batch-loss 14.1079 epoch-elapsed 0h01m23s total-elapsed 0h13m29s\n",
            "epoch 3 batch 32/89 processed 2,978 batch-loss 21.4440 epoch-elapsed 0h01m26s total-elapsed 0h13m32s\n",
            "epoch 3 batch 33/89 processed 2,988 batch-loss 27.7206 epoch-elapsed 0h01m30s total-elapsed 0h13m36s\n",
            "epoch 3 batch 34/89 processed 2,998 batch-loss 9.9944 epoch-elapsed 0h01m32s total-elapsed 0h13m38s\n",
            "epoch 3 batch 35/89 processed 3,008 batch-loss 17.0012 epoch-elapsed 0h01m34s total-elapsed 0h13m40s\n",
            "epoch 3 batch 36/89 processed 3,018 batch-loss 16.6221 epoch-elapsed 0h01m37s total-elapsed 0h13m43s\n",
            "epoch 3 batch 37/89 processed 3,028 batch-loss 15.3881 epoch-elapsed 0h01m39s total-elapsed 0h13m45s\n",
            "epoch 3 batch 38/89 processed 3,038 batch-loss 17.3485 epoch-elapsed 0h01m42s total-elapsed 0h13m48s\n",
            "epoch 3 batch 39/89 processed 3,048 batch-loss 14.6880 epoch-elapsed 0h01m45s total-elapsed 0h13m51s\n",
            "epoch 3 batch 40/89 processed 3,058 batch-loss 15.3082 epoch-elapsed 0h01m47s total-elapsed 0h13m53s\n",
            "epoch 3 batch 41/89 processed 3,068 batch-loss 16.5625 epoch-elapsed 0h01m50s total-elapsed 0h13m56s\n",
            "epoch 3 batch 42/89 processed 3,078 batch-loss 16.8922 epoch-elapsed 0h01m53s total-elapsed 0h13m59s\n",
            "epoch 3 batch 43/89 processed 3,088 batch-loss 19.3656 epoch-elapsed 0h01m56s total-elapsed 0h14m02s\n",
            "epoch 3 batch 44/89 processed 3,098 batch-loss 18.7964 epoch-elapsed 0h01m59s total-elapsed 0h14m05s\n",
            "epoch 3 batch 45/89 processed 3,108 batch-loss 12.2885 epoch-elapsed 0h02m01s total-elapsed 0h14m07s\n",
            "epoch 3 batch 46/89 processed 3,118 batch-loss 20.2430 epoch-elapsed 0h02m04s total-elapsed 0h14m10s\n",
            "epoch 3 batch 47/89 processed 3,128 batch-loss 14.5783 epoch-elapsed 0h02m06s total-elapsed 0h14m12s\n",
            "epoch 3 batch 48/89 processed 3,138 batch-loss 12.8947 epoch-elapsed 0h02m09s total-elapsed 0h14m15s\n",
            "epoch 3 batch 49/89 processed 3,148 batch-loss 18.6333 epoch-elapsed 0h02m12s total-elapsed 0h14m18s\n",
            "epoch 3 batch 50/89 processed 3,158 batch-loss 19.4556 epoch-elapsed 0h02m15s total-elapsed 0h14m21s\n",
            "epoch 3 batch 51/89 processed 3,168 batch-loss 15.7916 epoch-elapsed 0h02m18s total-elapsed 0h14m24s\n",
            "epoch 3 batch 52/89 processed 3,178 batch-loss 12.8053 epoch-elapsed 0h02m20s total-elapsed 0h14m26s\n",
            "epoch 3 batch 53/89 processed 3,188 batch-loss 25.4121 epoch-elapsed 0h02m24s total-elapsed 0h14m30s\n",
            "epoch 3 batch 54/89 processed 3,198 batch-loss 15.5959 epoch-elapsed 0h02m26s total-elapsed 0h14m32s\n",
            "epoch 3 batch 55/89 processed 3,208 batch-loss 16.2101 epoch-elapsed 0h02m29s total-elapsed 0h14m35s\n",
            "epoch 3 batch 56/89 processed 3,218 batch-loss 14.4788 epoch-elapsed 0h02m31s total-elapsed 0h14m37s\n",
            "epoch 3 batch 57/89 processed 3,228 batch-loss 12.5651 epoch-elapsed 0h02m34s total-elapsed 0h14m40s\n",
            "epoch 3 batch 58/89 processed 3,238 batch-loss 17.1526 epoch-elapsed 0h02m37s total-elapsed 0h14m43s\n",
            "epoch 3 batch 59/89 processed 3,248 batch-loss 18.1322 epoch-elapsed 0h02m40s total-elapsed 0h14m46s\n",
            "epoch 3 batch 60/89 processed 3,258 batch-loss 17.6219 epoch-elapsed 0h02m42s total-elapsed 0h14m48s\n",
            "epoch 3 batch 61/89 processed 3,268 batch-loss 21.2293 epoch-elapsed 0h02m46s total-elapsed 0h14m52s\n",
            "epoch 3 batch 62/89 processed 3,278 batch-loss 11.6186 epoch-elapsed 0h02m48s total-elapsed 0h14m54s\n",
            "epoch 3 batch 63/89 processed 3,288 batch-loss 16.8908 epoch-elapsed 0h02m51s total-elapsed 0h14m57s\n",
            "epoch 3 batch 64/89 processed 3,298 batch-loss 22.0841 epoch-elapsed 0h02m54s total-elapsed 0h15m00s\n",
            "epoch 3 batch 65/89 processed 3,308 batch-loss 17.3888 epoch-elapsed 0h02m57s total-elapsed 0h15m03s\n",
            "epoch 3 batch 66/89 processed 3,318 batch-loss 15.5414 epoch-elapsed 0h03m00s total-elapsed 0h15m05s\n",
            "epoch 3 batch 67/89 processed 3,328 batch-loss 14.1417 epoch-elapsed 0h03m02s total-elapsed 0h15m08s\n",
            "epoch 3 batch 68/89 processed 3,338 batch-loss 17.4894 epoch-elapsed 0h03m05s total-elapsed 0h15m11s\n",
            "epoch 3 batch 69/89 processed 3,348 batch-loss 12.2954 epoch-elapsed 0h03m07s total-elapsed 0h15m13s\n",
            "epoch 3 batch 70/89 processed 3,358 batch-loss 15.3383 epoch-elapsed 0h03m10s total-elapsed 0h15m16s\n",
            "epoch 3 batch 71/89 processed 3,368 batch-loss 16.1260 epoch-elapsed 0h03m13s total-elapsed 0h15m19s\n",
            "epoch 3 batch 72/89 processed 3,378 batch-loss 16.7294 epoch-elapsed 0h03m17s total-elapsed 0h15m22s\n",
            "epoch 3 batch 73/89 processed 3,388 batch-loss 9.2948 epoch-elapsed 0h03m19s total-elapsed 0h15m25s\n",
            "epoch 3 batch 74/89 processed 3,398 batch-loss 12.8097 epoch-elapsed 0h03m21s total-elapsed 0h15m27s\n",
            "epoch 3 batch 75/89 processed 3,408 batch-loss 14.1529 epoch-elapsed 0h03m24s total-elapsed 0h15m30s\n",
            "epoch 3 batch 76/89 processed 3,418 batch-loss 11.5538 epoch-elapsed 0h03m27s total-elapsed 0h15m32s\n",
            "epoch 3 batch 77/89 processed 3,428 batch-loss 8.8788 epoch-elapsed 0h03m28s total-elapsed 0h15m34s\n",
            "epoch 3 batch 78/89 processed 3,438 batch-loss 15.1002 epoch-elapsed 0h03m30s total-elapsed 0h15m36s\n",
            "epoch 3 batch 79/89 processed 3,448 batch-loss 15.7051 epoch-elapsed 0h03m33s total-elapsed 0h15m39s\n",
            "epoch 3 batch 80/89 processed 3,458 batch-loss 20.1345 epoch-elapsed 0h03m37s total-elapsed 0h15m43s\n",
            "epoch 3 batch 81/89 processed 3,468 batch-loss 9.9589 epoch-elapsed 0h03m39s total-elapsed 0h15m44s\n",
            "epoch 3 batch 82/89 processed 3,478 batch-loss 15.5097 epoch-elapsed 0h03m41s total-elapsed 0h15m47s\n",
            "epoch 3 batch 83/89 processed 3,488 batch-loss 10.0100 epoch-elapsed 0h03m43s total-elapsed 0h15m49s\n",
            "epoch 3 batch 84/89 processed 3,498 batch-loss 14.0859 epoch-elapsed 0h03m46s total-elapsed 0h15m52s\n",
            "epoch 3 batch 85/89 processed 3,508 batch-loss 18.3931 epoch-elapsed 0h03m49s total-elapsed 0h15m55s\n",
            "epoch 3 batch 86/89 processed 3,518 batch-loss 17.3384 epoch-elapsed 0h03m53s total-elapsed 0h15m58s\n",
            "epoch 3 batch 87/89 processed 3,528 batch-loss 8.7626 epoch-elapsed 0h03m54s total-elapsed 0h16m00s\n",
            "epoch 3 batch 88/89 processed 3,538 batch-loss 18.4811 epoch-elapsed 0h03m58s total-elapsed 0h16m04s\n",
            "epoch 3 batch 89/89 processed 3,544 batch-loss 8.5136 epoch-elapsed 0h03m59s total-elapsed 0h16m05s\n",
            "epoch 4 batch 1/89 processed 3,554 batch-loss 14.6630 epoch-elapsed 0h00m02s total-elapsed 0h16m08s\n",
            "epoch 4 batch 2/89 processed 3,564 batch-loss 17.2799 epoch-elapsed 0h00m06s total-elapsed 0h16m11s\n",
            "epoch 4 batch 3/89 processed 3,574 batch-loss 11.1687 epoch-elapsed 0h00m08s total-elapsed 0h16m14s\n",
            "epoch 4 batch 4/89 processed 3,584 batch-loss 20.5100 epoch-elapsed 0h00m12s total-elapsed 0h16m17s\n",
            "epoch 4 batch 5/89 processed 3,594 batch-loss 14.4170 epoch-elapsed 0h00m16s total-elapsed 0h16m22s\n",
            "epoch 4 batch 6/89 processed 3,604 batch-loss 10.2693 epoch-elapsed 0h00m18s total-elapsed 0h16m24s\n",
            "epoch 4 batch 7/89 processed 3,614 batch-loss 11.1658 epoch-elapsed 0h00m20s total-elapsed 0h16m26s\n",
            "epoch 4 batch 8/89 processed 3,624 batch-loss 22.5744 epoch-elapsed 0h00m24s total-elapsed 0h16m30s\n",
            "epoch 4 batch 9/89 processed 3,634 batch-loss 10.8060 epoch-elapsed 0h00m27s total-elapsed 0h16m32s\n",
            "epoch 4 batch 10/89 processed 3,644 batch-loss 10.4300 epoch-elapsed 0h00m29s total-elapsed 0h16m34s\n",
            "epoch 4 batch 11/89 processed 3,654 batch-loss 10.9831 epoch-elapsed 0h00m31s total-elapsed 0h16m37s\n",
            "epoch 4 batch 12/89 processed 3,664 batch-loss 9.2821 epoch-elapsed 0h00m33s total-elapsed 0h16m39s\n",
            "epoch 4 batch 13/89 processed 3,674 batch-loss 16.6840 epoch-elapsed 0h00m36s total-elapsed 0h16m42s\n",
            "epoch 4 batch 14/89 processed 3,684 batch-loss 14.5268 epoch-elapsed 0h00m39s total-elapsed 0h16m44s\n",
            "epoch 4 batch 15/89 processed 3,694 batch-loss 9.5859 epoch-elapsed 0h00m40s total-elapsed 0h16m46s\n",
            "epoch 4 batch 16/89 processed 3,704 batch-loss 18.4144 epoch-elapsed 0h00m44s total-elapsed 0h16m50s\n",
            "epoch 4 batch 17/89 processed 3,714 batch-loss 11.7562 epoch-elapsed 0h00m46s total-elapsed 0h16m52s\n",
            "epoch 4 batch 18/89 processed 3,724 batch-loss 9.9008 epoch-elapsed 0h00m49s total-elapsed 0h16m54s\n",
            "epoch 4 batch 19/89 processed 3,734 batch-loss 14.3352 epoch-elapsed 0h00m52s total-elapsed 0h16m58s\n",
            "epoch 4 batch 20/89 processed 3,744 batch-loss 7.9816 epoch-elapsed 0h00m54s total-elapsed 0h17m00s\n",
            "epoch 4 batch 21/89 processed 3,754 batch-loss 18.3815 epoch-elapsed 0h00m56s total-elapsed 0h17m02s\n",
            "epoch 4 batch 22/89 processed 3,764 batch-loss 14.8013 epoch-elapsed 0h01m00s total-elapsed 0h17m06s\n",
            "epoch 4 batch 23/89 processed 3,774 batch-loss 11.7130 epoch-elapsed 0h01m03s total-elapsed 0h17m08s\n",
            "epoch 4 batch 24/89 processed 3,784 batch-loss 12.0497 epoch-elapsed 0h01m05s total-elapsed 0h17m11s\n",
            "epoch 4 batch 25/89 processed 3,794 batch-loss 11.7217 epoch-elapsed 0h01m07s total-elapsed 0h17m13s\n",
            "epoch 4 batch 26/89 processed 3,804 batch-loss 19.8405 epoch-elapsed 0h01m12s total-elapsed 0h17m18s\n",
            "epoch 4 batch 27/89 processed 3,814 batch-loss 13.6287 epoch-elapsed 0h01m14s total-elapsed 0h17m20s\n",
            "epoch 4 batch 28/89 processed 3,824 batch-loss 19.7920 epoch-elapsed 0h01m18s total-elapsed 0h17m23s\n",
            "epoch 4 batch 29/89 processed 3,834 batch-loss 15.0489 epoch-elapsed 0h01m20s total-elapsed 0h17m26s\n",
            "epoch 4 batch 30/89 processed 3,844 batch-loss 6.9299 epoch-elapsed 0h01m22s total-elapsed 0h17m28s\n",
            "epoch 4 batch 31/89 processed 3,854 batch-loss 12.1628 epoch-elapsed 0h01m24s total-elapsed 0h17m30s\n",
            "epoch 4 batch 32/89 processed 3,864 batch-loss 10.6601 epoch-elapsed 0h01m27s total-elapsed 0h17m33s\n",
            "epoch 4 batch 33/89 processed 3,874 batch-loss 13.7872 epoch-elapsed 0h01m29s total-elapsed 0h17m35s\n",
            "epoch 4 batch 34/89 processed 3,884 batch-loss 9.7446 epoch-elapsed 0h01m31s total-elapsed 0h17m37s\n",
            "epoch 4 batch 35/89 processed 3,894 batch-loss 9.1189 epoch-elapsed 0h01m33s total-elapsed 0h17m39s\n",
            "epoch 4 batch 36/89 processed 3,904 batch-loss 14.4763 epoch-elapsed 0h01m36s total-elapsed 0h17m42s\n",
            "epoch 4 batch 37/89 processed 3,914 batch-loss 14.7257 epoch-elapsed 0h01m39s total-elapsed 0h17m45s\n",
            "epoch 4 batch 38/89 processed 3,924 batch-loss 18.2969 epoch-elapsed 0h01m42s total-elapsed 0h17m48s\n",
            "epoch 4 batch 39/89 processed 3,934 batch-loss 14.9776 epoch-elapsed 0h01m45s total-elapsed 0h17m50s\n",
            "epoch 4 batch 40/89 processed 3,944 batch-loss 15.7761 epoch-elapsed 0h01m47s total-elapsed 0h17m53s\n",
            "epoch 4 batch 41/89 processed 3,954 batch-loss 13.3496 epoch-elapsed 0h01m50s total-elapsed 0h17m56s\n",
            "epoch 4 batch 42/89 processed 3,964 batch-loss 8.6569 epoch-elapsed 0h01m52s total-elapsed 0h17m57s\n",
            "epoch 4 batch 43/89 processed 3,974 batch-loss 15.8981 epoch-elapsed 0h01m54s total-elapsed 0h18m00s\n",
            "epoch 4 batch 44/89 processed 3,984 batch-loss 13.1198 epoch-elapsed 0h01m57s total-elapsed 0h18m03s\n",
            "epoch 4 batch 45/89 processed 3,994 batch-loss 16.5605 epoch-elapsed 0h02m00s total-elapsed 0h18m06s\n",
            "epoch 4 batch 46/89 processed 4,004 batch-loss 13.7039 epoch-elapsed 0h02m03s total-elapsed 0h18m09s\n",
            "epoch 4 batch 47/89 processed 4,014 batch-loss 14.3787 epoch-elapsed 0h02m06s total-elapsed 0h18m12s\n",
            "epoch 4 batch 48/89 processed 4,024 batch-loss 10.1036 epoch-elapsed 0h02m08s total-elapsed 0h18m14s\n",
            "epoch 4 batch 49/89 processed 4,034 batch-loss 8.5729 epoch-elapsed 0h02m10s total-elapsed 0h18m16s\n",
            "epoch 4 batch 50/89 processed 4,044 batch-loss 17.1096 epoch-elapsed 0h02m14s total-elapsed 0h18m19s\n",
            "epoch 4 batch 51/89 processed 4,054 batch-loss 17.3196 epoch-elapsed 0h02m17s total-elapsed 0h18m23s\n",
            "epoch 4 batch 52/89 processed 4,064 batch-loss 15.2105 epoch-elapsed 0h02m19s total-elapsed 0h18m25s\n",
            "epoch 4 batch 53/89 processed 4,074 batch-loss 11.2616 epoch-elapsed 0h02m22s total-elapsed 0h18m28s\n",
            "epoch 4 batch 54/89 processed 4,084 batch-loss 13.7204 epoch-elapsed 0h02m24s total-elapsed 0h18m30s\n",
            "epoch 4 batch 55/89 processed 4,094 batch-loss 21.7981 epoch-elapsed 0h02m28s total-elapsed 0h18m34s\n",
            "epoch 4 batch 56/89 processed 4,104 batch-loss 9.5524 epoch-elapsed 0h02m30s total-elapsed 0h18m36s\n",
            "epoch 4 batch 57/89 processed 4,114 batch-loss 12.4412 epoch-elapsed 0h02m33s total-elapsed 0h18m39s\n",
            "epoch 4 batch 58/89 processed 4,124 batch-loss 6.1622 epoch-elapsed 0h02m35s total-elapsed 0h18m40s\n",
            "epoch 4 batch 59/89 processed 4,134 batch-loss 19.3488 epoch-elapsed 0h02m39s total-elapsed 0h18m45s\n",
            "epoch 4 batch 60/89 processed 4,144 batch-loss 10.3079 epoch-elapsed 0h02m41s total-elapsed 0h18m47s\n",
            "epoch 4 batch 61/89 processed 4,154 batch-loss 13.5493 epoch-elapsed 0h02m44s total-elapsed 0h18m50s\n",
            "epoch 4 batch 62/89 processed 4,164 batch-loss 11.2880 epoch-elapsed 0h02m47s total-elapsed 0h18m53s\n",
            "epoch 4 batch 63/89 processed 4,174 batch-loss 11.9910 epoch-elapsed 0h02m49s total-elapsed 0h18m55s\n",
            "epoch 4 batch 64/89 processed 4,184 batch-loss 7.3008 epoch-elapsed 0h02m51s total-elapsed 0h18m56s\n",
            "epoch 4 batch 65/89 processed 4,194 batch-loss 16.5157 epoch-elapsed 0h02m54s total-elapsed 0h19m00s\n",
            "epoch 4 batch 66/89 processed 4,204 batch-loss 16.7481 epoch-elapsed 0h02m57s total-elapsed 0h19m03s\n",
            "epoch 4 batch 67/89 processed 4,214 batch-loss 17.7872 epoch-elapsed 0h03m01s total-elapsed 0h19m06s\n",
            "epoch 4 batch 68/89 processed 4,224 batch-loss 13.2330 epoch-elapsed 0h03m03s total-elapsed 0h19m09s\n",
            "epoch 4 batch 69/89 processed 4,234 batch-loss 14.2408 epoch-elapsed 0h03m06s total-elapsed 0h19m12s\n",
            "epoch 4 batch 70/89 processed 4,244 batch-loss 12.1593 epoch-elapsed 0h03m09s total-elapsed 0h19m15s\n",
            "epoch 4 batch 71/89 processed 4,254 batch-loss 11.7837 epoch-elapsed 0h03m11s total-elapsed 0h19m17s\n",
            "epoch 4 batch 72/89 processed 4,264 batch-loss 14.7293 epoch-elapsed 0h03m14s total-elapsed 0h19m20s\n",
            "epoch 4 batch 73/89 processed 4,274 batch-loss 16.6384 epoch-elapsed 0h03m17s total-elapsed 0h19m23s\n",
            "epoch 4 batch 74/89 processed 4,284 batch-loss 12.6988 epoch-elapsed 0h03m20s total-elapsed 0h19m26s\n",
            "epoch 4 batch 75/89 processed 4,294 batch-loss 13.1491 epoch-elapsed 0h03m23s total-elapsed 0h19m29s\n",
            "epoch 4 batch 76/89 processed 4,304 batch-loss 10.6697 epoch-elapsed 0h03m25s total-elapsed 0h19m31s\n",
            "epoch 4 batch 77/89 processed 4,314 batch-loss 8.9872 epoch-elapsed 0h03m27s total-elapsed 0h19m33s\n",
            "epoch 4 batch 78/89 processed 4,324 batch-loss 10.8003 epoch-elapsed 0h03m30s total-elapsed 0h19m36s\n",
            "epoch 4 batch 79/89 processed 4,334 batch-loss 11.3103 epoch-elapsed 0h03m32s total-elapsed 0h19m38s\n",
            "epoch 4 batch 80/89 processed 4,344 batch-loss 16.0592 epoch-elapsed 0h03m36s total-elapsed 0h19m42s\n",
            "epoch 4 batch 81/89 processed 4,354 batch-loss 13.0107 epoch-elapsed 0h03m38s total-elapsed 0h19m44s\n",
            "epoch 4 batch 82/89 processed 4,364 batch-loss 13.1152 epoch-elapsed 0h03m42s total-elapsed 0h19m48s\n",
            "epoch 4 batch 83/89 processed 4,374 batch-loss 14.8798 epoch-elapsed 0h03m45s total-elapsed 0h19m51s\n",
            "epoch 4 batch 84/89 processed 4,384 batch-loss 17.9908 epoch-elapsed 0h03m48s total-elapsed 0h19m54s\n",
            "epoch 4 batch 85/89 processed 4,394 batch-loss 18.1190 epoch-elapsed 0h03m52s total-elapsed 0h19m57s\n",
            "epoch 4 batch 86/89 processed 4,404 batch-loss 11.8341 epoch-elapsed 0h03m54s total-elapsed 0h20m00s\n",
            "epoch 4 batch 87/89 processed 4,414 batch-loss 8.7766 epoch-elapsed 0h03m57s total-elapsed 0h20m02s\n",
            "epoch 4 batch 88/89 processed 4,424 batch-loss 8.2697 epoch-elapsed 0h03m59s total-elapsed 0h20m05s\n",
            "epoch 4 batch 89/89 processed 4,430 batch-loss 13.0649 epoch-elapsed 0h04m00s total-elapsed 0h20m06s\n",
            "epoch 5 batch 1/89 processed 4,440 batch-loss 12.9045 epoch-elapsed 0h00m02s total-elapsed 0h20m09s\n",
            "epoch 5 batch 2/89 processed 4,450 batch-loss 6.5389 epoch-elapsed 0h00m05s total-elapsed 0h20m11s\n",
            "epoch 5 batch 3/89 processed 4,460 batch-loss 5.9711 epoch-elapsed 0h00m06s total-elapsed 0h20m13s\n",
            "epoch 5 batch 4/89 processed 4,470 batch-loss 12.0696 epoch-elapsed 0h00m09s total-elapsed 0h20m16s\n",
            "epoch 5 batch 5/89 processed 4,480 batch-loss 7.6831 epoch-elapsed 0h00m11s total-elapsed 0h20m18s\n",
            "epoch 5 batch 6/89 processed 4,490 batch-loss 14.3632 epoch-elapsed 0h00m14s total-elapsed 0h20m21s\n",
            "epoch 5 batch 7/89 processed 4,500 batch-loss 12.5662 epoch-elapsed 0h00m17s total-elapsed 0h20m24s\n",
            "epoch 5 batch 8/89 processed 4,510 batch-loss 13.8967 epoch-elapsed 0h00m20s total-elapsed 0h20m27s\n",
            "epoch 5 batch 9/89 processed 4,520 batch-loss 13.8108 epoch-elapsed 0h00m24s total-elapsed 0h20m30s\n",
            "epoch 5 batch 10/89 processed 4,530 batch-loss 15.6154 epoch-elapsed 0h00m27s total-elapsed 0h20m34s\n",
            "epoch 5 batch 11/89 processed 4,540 batch-loss 10.0589 epoch-elapsed 0h00m30s total-elapsed 0h20m37s\n",
            "epoch 5 batch 12/89 processed 4,550 batch-loss 15.5956 epoch-elapsed 0h00m33s total-elapsed 0h20m40s\n",
            "epoch 5 batch 13/89 processed 4,560 batch-loss 14.7934 epoch-elapsed 0h00m36s total-elapsed 0h20m43s\n",
            "epoch 5 batch 14/89 processed 4,570 batch-loss 12.0734 epoch-elapsed 0h00m38s total-elapsed 0h20m45s\n",
            "epoch 5 batch 15/89 processed 4,580 batch-loss 16.7014 epoch-elapsed 0h00m41s total-elapsed 0h20m48s\n",
            "epoch 5 batch 16/89 processed 4,590 batch-loss 12.1984 epoch-elapsed 0h00m44s total-elapsed 0h20m51s\n",
            "epoch 5 batch 17/89 processed 4,600 batch-loss 12.0801 epoch-elapsed 0h00m47s total-elapsed 0h20m54s\n",
            "epoch 5 batch 18/89 processed 4,610 batch-loss 13.3351 epoch-elapsed 0h00m50s total-elapsed 0h20m57s\n",
            "epoch 5 batch 19/89 processed 4,620 batch-loss 12.3354 epoch-elapsed 0h00m53s total-elapsed 0h20m59s\n",
            "epoch 5 batch 20/89 processed 4,630 batch-loss 8.5516 epoch-elapsed 0h00m55s total-elapsed 0h21m02s\n",
            "epoch 5 batch 21/89 processed 4,640 batch-loss 8.4716 epoch-elapsed 0h00m57s total-elapsed 0h21m04s\n",
            "epoch 5 batch 22/89 processed 4,650 batch-loss 9.6412 epoch-elapsed 0h00m59s total-elapsed 0h21m06s\n",
            "epoch 5 batch 23/89 processed 4,660 batch-loss 10.5185 epoch-elapsed 0h01m02s total-elapsed 0h21m08s\n",
            "epoch 5 batch 24/89 processed 4,670 batch-loss 9.7340 epoch-elapsed 0h01m04s total-elapsed 0h21m11s\n",
            "epoch 5 batch 25/89 processed 4,680 batch-loss 13.7929 epoch-elapsed 0h01m07s total-elapsed 0h21m14s\n",
            "epoch 5 batch 26/89 processed 4,690 batch-loss 8.3093 epoch-elapsed 0h01m10s total-elapsed 0h21m16s\n",
            "epoch 5 batch 27/89 processed 4,700 batch-loss 13.0542 epoch-elapsed 0h01m12s total-elapsed 0h21m19s\n",
            "epoch 5 batch 28/89 processed 4,710 batch-loss 10.8624 epoch-elapsed 0h01m15s total-elapsed 0h21m21s\n",
            "epoch 5 batch 29/89 processed 4,720 batch-loss 12.6204 epoch-elapsed 0h01m18s total-elapsed 0h21m24s\n",
            "epoch 5 batch 30/89 processed 4,730 batch-loss 11.5343 epoch-elapsed 0h01m21s total-elapsed 0h21m27s\n",
            "epoch 5 batch 31/89 processed 4,740 batch-loss 7.7893 epoch-elapsed 0h01m23s total-elapsed 0h21m29s\n",
            "epoch 5 batch 32/89 processed 4,750 batch-loss 11.5428 epoch-elapsed 0h01m25s total-elapsed 0h21m32s\n",
            "epoch 5 batch 33/89 processed 4,760 batch-loss 13.4762 epoch-elapsed 0h01m28s total-elapsed 0h21m35s\n",
            "epoch 5 batch 34/89 processed 4,770 batch-loss 9.8569 epoch-elapsed 0h01m31s total-elapsed 0h21m37s\n",
            "epoch 5 batch 35/89 processed 4,780 batch-loss 12.7425 epoch-elapsed 0h01m33s total-elapsed 0h21m40s\n",
            "epoch 5 batch 36/89 processed 4,790 batch-loss 21.7576 epoch-elapsed 0h01m37s total-elapsed 0h21m44s\n",
            "epoch 5 batch 37/89 processed 4,800 batch-loss 12.0065 epoch-elapsed 0h01m40s total-elapsed 0h21m46s\n",
            "epoch 5 batch 38/89 processed 4,810 batch-loss 10.4035 epoch-elapsed 0h01m42s total-elapsed 0h21m49s\n",
            "epoch 5 batch 39/89 processed 4,820 batch-loss 9.4932 epoch-elapsed 0h01m44s total-elapsed 0h21m51s\n",
            "epoch 5 batch 40/89 processed 4,830 batch-loss 10.9824 epoch-elapsed 0h01m47s total-elapsed 0h21m54s\n",
            "epoch 5 batch 41/89 processed 4,840 batch-loss 12.5868 epoch-elapsed 0h01m50s total-elapsed 0h21m56s\n",
            "epoch 5 batch 42/89 processed 4,850 batch-loss 10.8751 epoch-elapsed 0h01m52s total-elapsed 0h21m59s\n",
            "epoch 5 batch 43/89 processed 4,860 batch-loss 13.6769 epoch-elapsed 0h01m56s total-elapsed 0h22m03s\n",
            "epoch 5 batch 44/89 processed 4,870 batch-loss 11.7966 epoch-elapsed 0h01m59s total-elapsed 0h22m06s\n",
            "epoch 5 batch 45/89 processed 4,880 batch-loss 6.9629 epoch-elapsed 0h02m01s total-elapsed 0h22m07s\n",
            "epoch 5 batch 46/89 processed 4,890 batch-loss 15.2554 epoch-elapsed 0h02m04s total-elapsed 0h22m10s\n",
            "epoch 5 batch 47/89 processed 4,900 batch-loss 10.9164 epoch-elapsed 0h02m06s total-elapsed 0h22m13s\n",
            "epoch 5 batch 48/89 processed 4,910 batch-loss 15.0005 epoch-elapsed 0h02m09s total-elapsed 0h22m16s\n",
            "epoch 5 batch 49/89 processed 4,920 batch-loss 11.8517 epoch-elapsed 0h02m12s total-elapsed 0h22m18s\n",
            "epoch 5 batch 50/89 processed 4,930 batch-loss 7.3371 epoch-elapsed 0h02m14s total-elapsed 0h22m20s\n",
            "epoch 5 batch 51/89 processed 4,940 batch-loss 9.9544 epoch-elapsed 0h02m16s total-elapsed 0h22m23s\n",
            "epoch 5 batch 52/89 processed 4,950 batch-loss 9.3603 epoch-elapsed 0h02m18s total-elapsed 0h22m25s\n",
            "epoch 5 batch 53/89 processed 4,960 batch-loss 15.4937 epoch-elapsed 0h02m22s total-elapsed 0h22m29s\n",
            "epoch 5 batch 54/89 processed 4,970 batch-loss 13.2742 epoch-elapsed 0h02m25s total-elapsed 0h22m32s\n",
            "epoch 5 batch 55/89 processed 4,980 batch-loss 13.9823 epoch-elapsed 0h02m28s total-elapsed 0h22m35s\n",
            "epoch 5 batch 56/89 processed 4,990 batch-loss 10.7249 epoch-elapsed 0h02m31s total-elapsed 0h22m38s\n",
            "epoch 5 batch 57/89 processed 5,000 batch-loss 8.4091 epoch-elapsed 0h02m33s total-elapsed 0h22m40s\n",
            "epoch 5 batch 58/89 processed 5,010 batch-loss 11.2530 epoch-elapsed 0h02m35s total-elapsed 0h22m42s\n",
            "epoch 5 batch 59/89 processed 5,020 batch-loss 11.1116 epoch-elapsed 0h02m38s total-elapsed 0h22m45s\n",
            "epoch 5 batch 60/89 processed 5,030 batch-loss 13.3411 epoch-elapsed 0h02m41s total-elapsed 0h22m48s\n",
            "epoch 5 batch 61/89 processed 5,040 batch-loss 12.6589 epoch-elapsed 0h02m44s total-elapsed 0h22m50s\n",
            "epoch 5 batch 62/89 processed 5,050 batch-loss 12.2051 epoch-elapsed 0h02m46s total-elapsed 0h22m53s\n",
            "epoch 5 batch 63/89 processed 5,060 batch-loss 10.9419 epoch-elapsed 0h02m49s total-elapsed 0h22m56s\n",
            "epoch 5 batch 64/89 processed 5,070 batch-loss 8.8334 epoch-elapsed 0h02m52s total-elapsed 0h22m58s\n",
            "epoch 5 batch 65/89 processed 5,080 batch-loss 11.4245 epoch-elapsed 0h02m54s total-elapsed 0h23m01s\n",
            "epoch 5 batch 66/89 processed 5,090 batch-loss 7.5565 epoch-elapsed 0h02m55s total-elapsed 0h23m02s\n",
            "epoch 5 batch 67/89 processed 5,100 batch-loss 14.0238 epoch-elapsed 0h02m58s total-elapsed 0h23m05s\n",
            "epoch 5 batch 68/89 processed 5,110 batch-loss 8.3850 epoch-elapsed 0h03m01s total-elapsed 0h23m07s\n",
            "epoch 5 batch 69/89 processed 5,120 batch-loss 13.7908 epoch-elapsed 0h03m04s total-elapsed 0h23m10s\n",
            "epoch 5 batch 70/89 processed 5,130 batch-loss 11.2473 epoch-elapsed 0h03m06s total-elapsed 0h23m13s\n",
            "epoch 5 batch 71/89 processed 5,140 batch-loss 12.3556 epoch-elapsed 0h03m09s total-elapsed 0h23m16s\n",
            "epoch 5 batch 72/89 processed 5,150 batch-loss 10.4084 epoch-elapsed 0h03m11s total-elapsed 0h23m18s\n",
            "epoch 5 batch 73/89 processed 5,160 batch-loss 10.5608 epoch-elapsed 0h03m15s total-elapsed 0h23m22s\n",
            "epoch 5 batch 74/89 processed 5,170 batch-loss 9.4594 epoch-elapsed 0h03m18s total-elapsed 0h23m24s\n",
            "epoch 5 batch 75/89 processed 5,180 batch-loss 11.3073 epoch-elapsed 0h03m20s total-elapsed 0h23m27s\n",
            "epoch 5 batch 76/89 processed 5,190 batch-loss 14.0388 epoch-elapsed 0h03m23s total-elapsed 0h23m30s\n",
            "epoch 5 batch 77/89 processed 5,200 batch-loss 12.7092 epoch-elapsed 0h03m26s total-elapsed 0h23m32s\n",
            "epoch 5 batch 78/89 processed 5,210 batch-loss 14.0662 epoch-elapsed 0h03m29s total-elapsed 0h23m35s\n",
            "epoch 5 batch 79/89 processed 5,220 batch-loss 12.6305 epoch-elapsed 0h03m31s total-elapsed 0h23m38s\n",
            "epoch 5 batch 80/89 processed 5,230 batch-loss 9.9770 epoch-elapsed 0h03m33s total-elapsed 0h23m40s\n",
            "epoch 5 batch 81/89 processed 5,240 batch-loss 14.7177 epoch-elapsed 0h03m37s total-elapsed 0h23m43s\n",
            "epoch 5 batch 82/89 processed 5,250 batch-loss 11.9298 epoch-elapsed 0h03m40s total-elapsed 0h23m46s\n",
            "epoch 5 batch 83/89 processed 5,260 batch-loss 13.0165 epoch-elapsed 0h03m43s total-elapsed 0h23m49s\n",
            "epoch 5 batch 84/89 processed 5,270 batch-loss 10.3596 epoch-elapsed 0h03m46s total-elapsed 0h23m52s\n",
            "epoch 5 batch 85/89 processed 5,280 batch-loss 10.7474 epoch-elapsed 0h03m48s total-elapsed 0h23m55s\n",
            "epoch 5 batch 86/89 processed 5,290 batch-loss 9.5435 epoch-elapsed 0h03m51s total-elapsed 0h23m58s\n",
            "epoch 5 batch 87/89 processed 5,300 batch-loss 15.4258 epoch-elapsed 0h03m54s total-elapsed 0h24m01s\n",
            "epoch 5 batch 88/89 processed 5,310 batch-loss 6.3785 epoch-elapsed 0h03m56s total-elapsed 0h24m03s\n",
            "epoch 5 batch 89/89 processed 5,316 batch-loss 9.6401 epoch-elapsed 0h03m58s total-elapsed 0h24m04s\n",
            "epoch 6 batch 1/89 processed 5,326 batch-loss 5.5867 epoch-elapsed 0h00m01s total-elapsed 0h24m06s\n",
            "epoch 6 batch 2/89 processed 5,336 batch-loss 7.2847 epoch-elapsed 0h00m04s total-elapsed 0h24m08s\n",
            "epoch 6 batch 3/89 processed 5,346 batch-loss 10.6378 epoch-elapsed 0h00m06s total-elapsed 0h24m10s\n",
            "epoch 6 batch 4/89 processed 5,356 batch-loss 7.8794 epoch-elapsed 0h00m08s total-elapsed 0h24m13s\n",
            "epoch 6 batch 5/89 processed 5,366 batch-loss 11.7059 epoch-elapsed 0h00m11s total-elapsed 0h24m16s\n",
            "epoch 6 batch 6/89 processed 5,376 batch-loss 10.4355 epoch-elapsed 0h00m14s total-elapsed 0h24m19s\n",
            "epoch 6 batch 7/89 processed 5,386 batch-loss 8.3833 epoch-elapsed 0h00m17s total-elapsed 0h24m21s\n",
            "epoch 6 batch 8/89 processed 5,396 batch-loss 8.0919 epoch-elapsed 0h00m19s total-elapsed 0h24m24s\n",
            "epoch 6 batch 9/89 processed 5,406 batch-loss 6.8233 epoch-elapsed 0h00m22s total-elapsed 0h24m26s\n",
            "epoch 6 batch 10/89 processed 5,416 batch-loss 11.9128 epoch-elapsed 0h00m25s total-elapsed 0h24m30s\n",
            "epoch 6 batch 11/89 processed 5,426 batch-loss 7.6630 epoch-elapsed 0h00m27s total-elapsed 0h24m32s\n",
            "epoch 6 batch 12/89 processed 5,436 batch-loss 10.1120 epoch-elapsed 0h00m30s total-elapsed 0h24m34s\n",
            "epoch 6 batch 13/89 processed 5,446 batch-loss 7.2489 epoch-elapsed 0h00m32s total-elapsed 0h24m36s\n",
            "epoch 6 batch 14/89 processed 5,456 batch-loss 7.9977 epoch-elapsed 0h00m34s total-elapsed 0h24m39s\n",
            "epoch 6 batch 15/89 processed 5,466 batch-loss 7.9130 epoch-elapsed 0h00m37s total-elapsed 0h24m41s\n",
            "epoch 6 batch 16/89 processed 5,476 batch-loss 13.5399 epoch-elapsed 0h00m40s total-elapsed 0h24m44s\n",
            "epoch 6 batch 17/89 processed 5,486 batch-loss 10.9714 epoch-elapsed 0h00m42s total-elapsed 0h24m47s\n",
            "epoch 6 batch 18/89 processed 5,496 batch-loss 7.9960 epoch-elapsed 0h00m44s total-elapsed 0h24m49s\n",
            "epoch 6 batch 19/89 processed 5,506 batch-loss 8.1454 epoch-elapsed 0h00m46s total-elapsed 0h24m51s\n",
            "epoch 6 batch 20/89 processed 5,516 batch-loss 15.4205 epoch-elapsed 0h00m50s total-elapsed 0h24m55s\n",
            "epoch 6 batch 21/89 processed 5,526 batch-loss 9.8841 epoch-elapsed 0h00m53s total-elapsed 0h24m57s\n",
            "epoch 6 batch 22/89 processed 5,536 batch-loss 13.6814 epoch-elapsed 0h00m56s total-elapsed 0h25m01s\n",
            "epoch 6 batch 23/89 processed 5,546 batch-loss 20.8926 epoch-elapsed 0h01m00s total-elapsed 0h25m05s\n",
            "epoch 6 batch 24/89 processed 5,556 batch-loss 12.5132 epoch-elapsed 0h01m03s total-elapsed 0h25m08s\n",
            "epoch 6 batch 25/89 processed 5,566 batch-loss 11.1207 epoch-elapsed 0h01m06s total-elapsed 0h25m11s\n",
            "epoch 6 batch 26/89 processed 5,576 batch-loss 10.1942 epoch-elapsed 0h01m09s total-elapsed 0h25m13s\n",
            "epoch 6 batch 27/89 processed 5,586 batch-loss 8.3617 epoch-elapsed 0h01m12s total-elapsed 0h25m16s\n",
            "epoch 6 batch 28/89 processed 5,596 batch-loss 11.5878 epoch-elapsed 0h01m14s total-elapsed 0h25m19s\n",
            "epoch 6 batch 29/89 processed 5,606 batch-loss 10.6948 epoch-elapsed 0h01m18s total-elapsed 0h25m22s\n",
            "epoch 6 batch 30/89 processed 5,616 batch-loss 7.5456 epoch-elapsed 0h01m20s total-elapsed 0h25m25s\n",
            "epoch 6 batch 31/89 processed 5,626 batch-loss 7.7336 epoch-elapsed 0h01m22s total-elapsed 0h25m27s\n",
            "epoch 6 batch 32/89 processed 5,636 batch-loss 13.4968 epoch-elapsed 0h01m26s total-elapsed 0h25m30s\n",
            "epoch 6 batch 33/89 processed 5,646 batch-loss 17.5572 epoch-elapsed 0h01m29s total-elapsed 0h25m34s\n",
            "epoch 6 batch 34/89 processed 5,656 batch-loss 11.1921 epoch-elapsed 0h01m32s total-elapsed 0h25m37s\n",
            "epoch 6 batch 35/89 processed 5,666 batch-loss 10.3692 epoch-elapsed 0h01m35s total-elapsed 0h25m40s\n",
            "epoch 6 batch 36/89 processed 5,676 batch-loss 10.5142 epoch-elapsed 0h01m37s total-elapsed 0h25m42s\n",
            "epoch 6 batch 37/89 processed 5,686 batch-loss 11.4760 epoch-elapsed 0h01m40s total-elapsed 0h25m45s\n",
            "epoch 6 batch 38/89 processed 5,696 batch-loss 5.3871 epoch-elapsed 0h01m42s total-elapsed 0h25m47s\n",
            "epoch 6 batch 39/89 processed 5,706 batch-loss 6.4976 epoch-elapsed 0h01m44s total-elapsed 0h25m49s\n",
            "epoch 6 batch 40/89 processed 5,716 batch-loss 12.2668 epoch-elapsed 0h01m48s total-elapsed 0h25m52s\n",
            "epoch 6 batch 41/89 processed 5,726 batch-loss 7.6336 epoch-elapsed 0h01m50s total-elapsed 0h25m55s\n",
            "epoch 6 batch 42/89 processed 5,736 batch-loss 10.2374 epoch-elapsed 0h01m53s total-elapsed 0h25m57s\n",
            "epoch 6 batch 43/89 processed 5,746 batch-loss 13.1056 epoch-elapsed 0h01m55s total-elapsed 0h26m00s\n",
            "epoch 6 batch 44/89 processed 5,756 batch-loss 9.7628 epoch-elapsed 0h01m57s total-elapsed 0h26m02s\n",
            "epoch 6 batch 45/89 processed 5,766 batch-loss 17.7710 epoch-elapsed 0h02m02s total-elapsed 0h26m07s\n",
            "epoch 6 batch 46/89 processed 5,776 batch-loss 7.4888 epoch-elapsed 0h02m05s total-elapsed 0h26m09s\n",
            "epoch 6 batch 47/89 processed 5,786 batch-loss 7.3435 epoch-elapsed 0h02m07s total-elapsed 0h26m12s\n",
            "epoch 6 batch 48/89 processed 5,796 batch-loss 16.0961 epoch-elapsed 0h02m10s total-elapsed 0h26m15s\n",
            "epoch 6 batch 49/89 processed 5,806 batch-loss 15.7030 epoch-elapsed 0h02m14s total-elapsed 0h26m18s\n",
            "epoch 6 batch 50/89 processed 5,816 batch-loss 8.3817 epoch-elapsed 0h02m16s total-elapsed 0h26m20s\n",
            "epoch 6 batch 51/89 processed 5,826 batch-loss 11.2383 epoch-elapsed 0h02m18s total-elapsed 0h26m23s\n",
            "epoch 6 batch 52/89 processed 5,836 batch-loss 13.9162 epoch-elapsed 0h02m22s total-elapsed 0h26m27s\n",
            "epoch 6 batch 53/89 processed 5,846 batch-loss 11.1586 epoch-elapsed 0h02m24s total-elapsed 0h26m29s\n",
            "epoch 6 batch 54/89 processed 5,856 batch-loss 10.1279 epoch-elapsed 0h02m27s total-elapsed 0h26m32s\n",
            "epoch 6 batch 55/89 processed 5,866 batch-loss 13.8584 epoch-elapsed 0h02m30s total-elapsed 0h26m35s\n",
            "epoch 6 batch 56/89 processed 5,876 batch-loss 5.9566 epoch-elapsed 0h02m32s total-elapsed 0h26m37s\n",
            "epoch 6 batch 57/89 processed 5,886 batch-loss 8.2283 epoch-elapsed 0h02m34s total-elapsed 0h26m39s\n",
            "epoch 6 batch 58/89 processed 5,896 batch-loss 12.3632 epoch-elapsed 0h02m37s total-elapsed 0h26m42s\n",
            "epoch 6 batch 59/89 processed 5,906 batch-loss 8.6111 epoch-elapsed 0h02m40s total-elapsed 0h26m44s\n",
            "epoch 6 batch 60/89 processed 5,916 batch-loss 8.5160 epoch-elapsed 0h02m42s total-elapsed 0h26m47s\n",
            "epoch 6 batch 61/89 processed 5,926 batch-loss 12.8089 epoch-elapsed 0h02m45s total-elapsed 0h26m49s\n",
            "epoch 6 batch 62/89 processed 5,936 batch-loss 11.8762 epoch-elapsed 0h02m47s total-elapsed 0h26m52s\n",
            "epoch 6 batch 63/89 processed 5,946 batch-loss 11.1697 epoch-elapsed 0h02m50s total-elapsed 0h26m54s\n",
            "epoch 6 batch 64/89 processed 5,956 batch-loss 10.3532 epoch-elapsed 0h02m52s total-elapsed 0h26m57s\n",
            "epoch 6 batch 65/89 processed 5,966 batch-loss 5.5141 epoch-elapsed 0h02m55s total-elapsed 0h26m59s\n",
            "epoch 6 batch 66/89 processed 5,976 batch-loss 9.7383 epoch-elapsed 0h02m58s total-elapsed 0h27m03s\n",
            "epoch 6 batch 67/89 processed 5,986 batch-loss 5.5877 epoch-elapsed 0h03m00s total-elapsed 0h27m05s\n",
            "epoch 6 batch 68/89 processed 5,996 batch-loss 9.3903 epoch-elapsed 0h03m02s total-elapsed 0h27m07s\n",
            "epoch 6 batch 69/89 processed 6,006 batch-loss 7.2684 epoch-elapsed 0h03m04s total-elapsed 0h27m09s\n",
            "epoch 6 batch 70/89 processed 6,016 batch-loss 14.5638 epoch-elapsed 0h03m09s total-elapsed 0h27m13s\n",
            "epoch 6 batch 71/89 processed 6,026 batch-loss 9.9271 epoch-elapsed 0h03m11s total-elapsed 0h27m16s\n",
            "epoch 6 batch 72/89 processed 6,036 batch-loss 6.1564 epoch-elapsed 0h03m13s total-elapsed 0h27m18s\n",
            "epoch 6 batch 73/89 processed 6,046 batch-loss 9.0849 epoch-elapsed 0h03m16s total-elapsed 0h27m20s\n",
            "epoch 6 batch 74/89 processed 6,056 batch-loss 10.1563 epoch-elapsed 0h03m19s total-elapsed 0h27m23s\n",
            "epoch 6 batch 75/89 processed 6,066 batch-loss 12.3199 epoch-elapsed 0h03m22s total-elapsed 0h27m26s\n",
            "epoch 6 batch 76/89 processed 6,076 batch-loss 6.2973 epoch-elapsed 0h03m24s total-elapsed 0h27m29s\n",
            "epoch 6 batch 77/89 processed 6,086 batch-loss 13.6512 epoch-elapsed 0h03m27s total-elapsed 0h27m32s\n",
            "epoch 6 batch 78/89 processed 6,096 batch-loss 8.1532 epoch-elapsed 0h03m30s total-elapsed 0h27m34s\n",
            "epoch 6 batch 79/89 processed 6,106 batch-loss 12.3534 epoch-elapsed 0h03m33s total-elapsed 0h27m38s\n",
            "epoch 6 batch 80/89 processed 6,116 batch-loss 7.8162 epoch-elapsed 0h03m35s total-elapsed 0h27m40s\n",
            "epoch 6 batch 81/89 processed 6,126 batch-loss 7.8451 epoch-elapsed 0h03m38s total-elapsed 0h27m43s\n",
            "epoch 6 batch 82/89 processed 6,136 batch-loss 10.6331 epoch-elapsed 0h03m41s total-elapsed 0h27m45s\n",
            "epoch 6 batch 83/89 processed 6,146 batch-loss 18.5988 epoch-elapsed 0h03m44s total-elapsed 0h27m49s\n",
            "epoch 6 batch 84/89 processed 6,156 batch-loss 11.9977 epoch-elapsed 0h03m48s total-elapsed 0h27m52s\n",
            "epoch 6 batch 85/89 processed 6,166 batch-loss 10.5866 epoch-elapsed 0h03m50s total-elapsed 0h27m55s\n",
            "epoch 6 batch 86/89 processed 6,176 batch-loss 8.8792 epoch-elapsed 0h03m53s total-elapsed 0h27m58s\n",
            "epoch 6 batch 87/89 processed 6,186 batch-loss 11.2025 epoch-elapsed 0h03m55s total-elapsed 0h28m00s\n",
            "epoch 6 batch 88/89 processed 6,196 batch-loss 5.7722 epoch-elapsed 0h03m58s total-elapsed 0h28m02s\n",
            "epoch 6 batch 89/89 processed 6,202 batch-loss 11.2095 epoch-elapsed 0h03m59s total-elapsed 0h28m04s\n",
            "epoch 7 batch 1/89 processed 6,212 batch-loss 12.2149 epoch-elapsed 0h00m02s total-elapsed 0h28m06s\n",
            "epoch 7 batch 2/89 processed 6,222 batch-loss 17.5567 epoch-elapsed 0h00m07s total-elapsed 0h28m11s\n",
            "epoch 7 batch 3/89 processed 6,232 batch-loss 5.5935 epoch-elapsed 0h00m09s total-elapsed 0h28m13s\n",
            "epoch 7 batch 4/89 processed 6,242 batch-loss 7.8398 epoch-elapsed 0h00m11s total-elapsed 0h28m16s\n",
            "epoch 7 batch 5/89 processed 6,252 batch-loss 7.4435 epoch-elapsed 0h00m14s total-elapsed 0h28m18s\n",
            "epoch 7 batch 6/89 processed 6,262 batch-loss 12.8182 epoch-elapsed 0h00m17s total-elapsed 0h28m22s\n",
            "epoch 7 batch 7/89 processed 6,272 batch-loss 5.3809 epoch-elapsed 0h00m19s total-elapsed 0h28m24s\n",
            "epoch 7 batch 8/89 processed 6,282 batch-loss 8.4606 epoch-elapsed 0h00m22s total-elapsed 0h28m26s\n",
            "epoch 7 batch 9/89 processed 6,292 batch-loss 10.2946 epoch-elapsed 0h00m24s total-elapsed 0h28m29s\n",
            "epoch 7 batch 10/89 processed 6,302 batch-loss 7.0501 epoch-elapsed 0h00m27s total-elapsed 0h28m31s\n",
            "epoch 7 batch 11/89 processed 6,312 batch-loss 7.5119 epoch-elapsed 0h00m29s total-elapsed 0h28m33s\n",
            "epoch 7 batch 12/89 processed 6,322 batch-loss 7.9275 epoch-elapsed 0h00m31s total-elapsed 0h28m36s\n",
            "epoch 7 batch 13/89 processed 6,332 batch-loss 5.6106 epoch-elapsed 0h00m33s total-elapsed 0h28m38s\n",
            "epoch 7 batch 14/89 processed 6,342 batch-loss 10.0106 epoch-elapsed 0h00m37s total-elapsed 0h28m41s\n",
            "epoch 7 batch 15/89 processed 6,352 batch-loss 10.3844 epoch-elapsed 0h00m39s total-elapsed 0h28m44s\n",
            "epoch 7 batch 16/89 processed 6,362 batch-loss 7.9997 epoch-elapsed 0h00m42s total-elapsed 0h28m46s\n",
            "epoch 7 batch 17/89 processed 6,372 batch-loss 12.0305 epoch-elapsed 0h00m45s total-elapsed 0h28m49s\n",
            "epoch 7 batch 18/89 processed 6,382 batch-loss 9.3857 epoch-elapsed 0h00m47s total-elapsed 0h28m52s\n",
            "epoch 7 batch 19/89 processed 6,392 batch-loss 9.4715 epoch-elapsed 0h00m50s total-elapsed 0h28m54s\n",
            "epoch 7 batch 20/89 processed 6,402 batch-loss 14.1704 epoch-elapsed 0h00m54s total-elapsed 0h28m58s\n",
            "epoch 7 batch 21/89 processed 6,412 batch-loss 7.5452 epoch-elapsed 0h00m56s total-elapsed 0h29m00s\n",
            "epoch 7 batch 22/89 processed 6,422 batch-loss 3.9383 epoch-elapsed 0h00m57s total-elapsed 0h29m02s\n",
            "epoch 7 batch 23/89 processed 6,432 batch-loss 7.6465 epoch-elapsed 0h01m00s total-elapsed 0h29m04s\n",
            "epoch 7 batch 24/89 processed 6,442 batch-loss 8.0106 epoch-elapsed 0h01m02s total-elapsed 0h29m06s\n",
            "epoch 7 batch 25/89 processed 6,452 batch-loss 9.9245 epoch-elapsed 0h01m04s total-elapsed 0h29m09s\n",
            "epoch 7 batch 26/89 processed 6,462 batch-loss 13.6693 epoch-elapsed 0h01m08s total-elapsed 0h29m13s\n",
            "epoch 7 batch 27/89 processed 6,472 batch-loss 11.0209 epoch-elapsed 0h01m11s total-elapsed 0h29m16s\n",
            "epoch 7 batch 28/89 processed 6,482 batch-loss 10.3884 epoch-elapsed 0h01m14s total-elapsed 0h29m19s\n",
            "epoch 7 batch 29/89 processed 6,492 batch-loss 8.8930 epoch-elapsed 0h01m17s total-elapsed 0h29m21s\n",
            "epoch 7 batch 30/89 processed 6,502 batch-loss 10.4626 epoch-elapsed 0h01m19s total-elapsed 0h29m24s\n",
            "epoch 7 batch 31/89 processed 6,512 batch-loss 7.5074 epoch-elapsed 0h01m22s total-elapsed 0h29m26s\n",
            "epoch 7 batch 32/89 processed 6,522 batch-loss 12.0202 epoch-elapsed 0h01m24s total-elapsed 0h29m29s\n",
            "epoch 7 batch 33/89 processed 6,532 batch-loss 7.7163 epoch-elapsed 0h01m27s total-elapsed 0h29m31s\n",
            "epoch 7 batch 34/89 processed 6,542 batch-loss 11.9530 epoch-elapsed 0h01m30s total-elapsed 0h29m34s\n",
            "epoch 7 batch 35/89 processed 6,552 batch-loss 7.5706 epoch-elapsed 0h01m33s total-elapsed 0h29m37s\n",
            "epoch 7 batch 36/89 processed 6,562 batch-loss 12.5361 epoch-elapsed 0h01m36s total-elapsed 0h29m40s\n",
            "epoch 7 batch 37/89 processed 6,572 batch-loss 11.2281 epoch-elapsed 0h01m39s total-elapsed 0h29m43s\n",
            "epoch 7 batch 38/89 processed 6,582 batch-loss 10.2866 epoch-elapsed 0h01m42s total-elapsed 0h29m46s\n",
            "epoch 7 batch 39/89 processed 6,592 batch-loss 12.7152 epoch-elapsed 0h01m45s total-elapsed 0h29m50s\n",
            "epoch 7 batch 40/89 processed 6,602 batch-loss 7.4423 epoch-elapsed 0h01m48s total-elapsed 0h29m53s\n",
            "epoch 7 batch 41/89 processed 6,612 batch-loss 14.9702 epoch-elapsed 0h01m52s total-elapsed 0h29m57s\n",
            "epoch 7 batch 42/89 processed 6,622 batch-loss 8.3425 epoch-elapsed 0h01m54s total-elapsed 0h29m59s\n",
            "epoch 7 batch 43/89 processed 6,632 batch-loss 8.2785 epoch-elapsed 0h01m57s total-elapsed 0h30m01s\n",
            "epoch 7 batch 44/89 processed 6,642 batch-loss 6.5885 epoch-elapsed 0h01m59s total-elapsed 0h30m04s\n",
            "epoch 7 batch 45/89 processed 6,652 batch-loss 9.5340 epoch-elapsed 0h02m02s total-elapsed 0h30m06s\n",
            "epoch 7 batch 46/89 processed 6,662 batch-loss 14.4166 epoch-elapsed 0h02m05s total-elapsed 0h30m09s\n",
            "epoch 7 batch 47/89 processed 6,672 batch-loss 5.3900 epoch-elapsed 0h02m07s total-elapsed 0h30m11s\n",
            "epoch 7 batch 48/89 processed 6,682 batch-loss 6.9329 epoch-elapsed 0h02m09s total-elapsed 0h30m13s\n",
            "epoch 7 batch 49/89 processed 6,692 batch-loss 12.4857 epoch-elapsed 0h02m12s total-elapsed 0h30m16s\n",
            "epoch 7 batch 50/89 processed 6,702 batch-loss 5.4522 epoch-elapsed 0h02m14s total-elapsed 0h30m18s\n",
            "epoch 7 batch 51/89 processed 6,712 batch-loss 9.6489 epoch-elapsed 0h02m17s total-elapsed 0h30m21s\n",
            "epoch 7 batch 52/89 processed 6,722 batch-loss 8.1706 epoch-elapsed 0h02m20s total-elapsed 0h30m24s\n",
            "epoch 7 batch 53/89 processed 6,732 batch-loss 5.5763 epoch-elapsed 0h02m21s total-elapsed 0h30m26s\n",
            "epoch 7 batch 54/89 processed 6,742 batch-loss 10.1393 epoch-elapsed 0h02m24s total-elapsed 0h30m28s\n",
            "epoch 7 batch 55/89 processed 6,752 batch-loss 12.5480 epoch-elapsed 0h02m27s total-elapsed 0h30m32s\n",
            "epoch 7 batch 56/89 processed 6,762 batch-loss 8.1777 epoch-elapsed 0h02m31s total-elapsed 0h30m36s\n",
            "epoch 7 batch 57/89 processed 6,772 batch-loss 10.0420 epoch-elapsed 0h02m35s total-elapsed 0h30m39s\n",
            "epoch 7 batch 58/89 processed 6,782 batch-loss 12.0947 epoch-elapsed 0h02m37s total-elapsed 0h30m42s\n",
            "epoch 7 batch 59/89 processed 6,792 batch-loss 12.7544 epoch-elapsed 0h02m41s total-elapsed 0h30m45s\n",
            "epoch 7 batch 60/89 processed 6,802 batch-loss 10.0819 epoch-elapsed 0h02m44s total-elapsed 0h30m49s\n",
            "epoch 7 batch 61/89 processed 6,812 batch-loss 12.9406 epoch-elapsed 0h02m48s total-elapsed 0h30m52s\n",
            "epoch 7 batch 62/89 processed 6,822 batch-loss 6.7368 epoch-elapsed 0h02m50s total-elapsed 0h30m54s\n",
            "epoch 7 batch 63/89 processed 6,832 batch-loss 11.8368 epoch-elapsed 0h02m53s total-elapsed 0h30m57s\n",
            "epoch 7 batch 64/89 processed 6,842 batch-loss 5.1125 epoch-elapsed 0h02m54s total-elapsed 0h30m59s\n",
            "epoch 7 batch 65/89 processed 6,852 batch-loss 8.0369 epoch-elapsed 0h02m57s total-elapsed 0h31m01s\n",
            "epoch 7 batch 66/89 processed 6,862 batch-loss 10.5153 epoch-elapsed 0h03m00s total-elapsed 0h31m04s\n",
            "epoch 7 batch 67/89 processed 6,872 batch-loss 10.3374 epoch-elapsed 0h03m02s total-elapsed 0h31m07s\n",
            "epoch 7 batch 68/89 processed 6,882 batch-loss 7.3649 epoch-elapsed 0h03m05s total-elapsed 0h31m09s\n",
            "epoch 7 batch 69/89 processed 6,892 batch-loss 11.6588 epoch-elapsed 0h03m08s total-elapsed 0h31m12s\n",
            "epoch 7 batch 70/89 processed 6,902 batch-loss 7.2687 epoch-elapsed 0h03m10s total-elapsed 0h31m14s\n",
            "epoch 7 batch 71/89 processed 6,912 batch-loss 5.4026 epoch-elapsed 0h03m12s total-elapsed 0h31m17s\n",
            "epoch 7 batch 72/89 processed 6,922 batch-loss 9.2137 epoch-elapsed 0h03m15s total-elapsed 0h31m19s\n",
            "epoch 7 batch 73/89 processed 6,932 batch-loss 6.4823 epoch-elapsed 0h03m17s total-elapsed 0h31m22s\n",
            "epoch 7 batch 74/89 processed 6,942 batch-loss 9.5591 epoch-elapsed 0h03m20s total-elapsed 0h31m24s\n",
            "epoch 7 batch 75/89 processed 6,952 batch-loss 9.3971 epoch-elapsed 0h03m23s total-elapsed 0h31m27s\n",
            "epoch 7 batch 76/89 processed 6,962 batch-loss 5.3937 epoch-elapsed 0h03m25s total-elapsed 0h31m30s\n",
            "epoch 7 batch 77/89 processed 6,972 batch-loss 6.4063 epoch-elapsed 0h03m27s total-elapsed 0h31m32s\n",
            "epoch 7 batch 78/89 processed 6,982 batch-loss 11.3290 epoch-elapsed 0h03m31s total-elapsed 0h31m35s\n",
            "epoch 7 batch 79/89 processed 6,992 batch-loss 10.8150 epoch-elapsed 0h03m33s total-elapsed 0h31m37s\n",
            "epoch 7 batch 80/89 processed 7,002 batch-loss 7.1200 epoch-elapsed 0h03m35s total-elapsed 0h31m40s\n",
            "epoch 7 batch 81/89 processed 7,012 batch-loss 7.9277 epoch-elapsed 0h03m38s total-elapsed 0h31m42s\n",
            "epoch 7 batch 82/89 processed 7,022 batch-loss 10.8811 epoch-elapsed 0h03m40s total-elapsed 0h31m45s\n",
            "epoch 7 batch 83/89 processed 7,032 batch-loss 7.4023 epoch-elapsed 0h03m43s total-elapsed 0h31m47s\n",
            "epoch 7 batch 84/89 processed 7,042 batch-loss 5.5571 epoch-elapsed 0h03m45s total-elapsed 0h31m50s\n",
            "epoch 7 batch 85/89 processed 7,052 batch-loss 6.6453 epoch-elapsed 0h03m47s total-elapsed 0h31m52s\n",
            "epoch 7 batch 86/89 processed 7,062 batch-loss 9.9022 epoch-elapsed 0h03m50s total-elapsed 0h31m54s\n",
            "epoch 7 batch 87/89 processed 7,072 batch-loss 5.0576 epoch-elapsed 0h03m52s total-elapsed 0h31m57s\n",
            "epoch 7 batch 88/89 processed 7,082 batch-loss 7.9279 epoch-elapsed 0h03m54s total-elapsed 0h31m59s\n",
            "epoch 7 batch 89/89 processed 7,088 batch-loss 7.3748 epoch-elapsed 0h03m56s total-elapsed 0h32m00s\n",
            "epoch 8 batch 1/89 processed 7,098 batch-loss 9.4040 epoch-elapsed 0h00m02s total-elapsed 0h32m03s\n",
            "epoch 8 batch 2/89 processed 7,108 batch-loss 8.1910 epoch-elapsed 0h00m05s total-elapsed 0h32m05s\n",
            "epoch 8 batch 3/89 processed 7,118 batch-loss 6.8760 epoch-elapsed 0h00m07s total-elapsed 0h32m07s\n",
            "epoch 8 batch 4/89 processed 7,128 batch-loss 11.4753 epoch-elapsed 0h00m10s total-elapsed 0h32m11s\n",
            "epoch 8 batch 5/89 processed 7,138 batch-loss 11.1444 epoch-elapsed 0h00m14s total-elapsed 0h32m15s\n",
            "epoch 8 batch 6/89 processed 7,148 batch-loss 10.8996 epoch-elapsed 0h00m17s total-elapsed 0h32m18s\n",
            "epoch 8 batch 7/89 processed 7,158 batch-loss 6.9993 epoch-elapsed 0h00m19s total-elapsed 0h32m20s\n",
            "epoch 8 batch 8/89 processed 7,168 batch-loss 7.3669 epoch-elapsed 0h00m22s total-elapsed 0h32m22s\n",
            "epoch 8 batch 9/89 processed 7,178 batch-loss 9.3257 epoch-elapsed 0h00m25s total-elapsed 0h32m25s\n",
            "epoch 8 batch 10/89 processed 7,188 batch-loss 4.9371 epoch-elapsed 0h00m26s total-elapsed 0h32m27s\n",
            "epoch 8 batch 11/89 processed 7,198 batch-loss 10.9821 epoch-elapsed 0h00m29s total-elapsed 0h32m29s\n",
            "epoch 8 batch 12/89 processed 7,208 batch-loss 14.8829 epoch-elapsed 0h00m32s total-elapsed 0h32m33s\n",
            "epoch 8 batch 13/89 processed 7,218 batch-loss 7.2905 epoch-elapsed 0h00m35s total-elapsed 0h32m35s\n",
            "epoch 8 batch 14/89 processed 7,228 batch-loss 11.6152 epoch-elapsed 0h00m38s total-elapsed 0h32m39s\n",
            "epoch 8 batch 15/89 processed 7,238 batch-loss 6.2545 epoch-elapsed 0h00m41s total-elapsed 0h32m41s\n",
            "epoch 8 batch 16/89 processed 7,248 batch-loss 6.0761 epoch-elapsed 0h00m43s total-elapsed 0h32m44s\n",
            "epoch 8 batch 17/89 processed 7,258 batch-loss 4.9589 epoch-elapsed 0h00m45s total-elapsed 0h32m45s\n",
            "epoch 8 batch 18/89 processed 7,268 batch-loss 7.6347 epoch-elapsed 0h00m48s total-elapsed 0h32m48s\n",
            "epoch 8 batch 19/89 processed 7,278 batch-loss 8.2688 epoch-elapsed 0h00m50s total-elapsed 0h32m51s\n",
            "epoch 8 batch 20/89 processed 7,288 batch-loss 12.6276 epoch-elapsed 0h00m54s total-elapsed 0h32m54s\n",
            "epoch 8 batch 21/89 processed 7,298 batch-loss 6.4286 epoch-elapsed 0h00m56s total-elapsed 0h32m57s\n",
            "epoch 8 batch 22/89 processed 7,308 batch-loss 10.3773 epoch-elapsed 0h00m58s total-elapsed 0h32m59s\n",
            "epoch 8 batch 23/89 processed 7,318 batch-loss 8.7391 epoch-elapsed 0h01m02s total-elapsed 0h33m02s\n",
            "epoch 8 batch 24/89 processed 7,328 batch-loss 4.7497 epoch-elapsed 0h01m03s total-elapsed 0h33m04s\n",
            "epoch 8 batch 25/89 processed 7,338 batch-loss 5.6137 epoch-elapsed 0h01m05s total-elapsed 0h33m06s\n",
            "epoch 8 batch 26/89 processed 7,348 batch-loss 6.4572 epoch-elapsed 0h01m08s total-elapsed 0h33m08s\n",
            "epoch 8 batch 27/89 processed 7,358 batch-loss 5.4642 epoch-elapsed 0h01m10s total-elapsed 0h33m10s\n",
            "epoch 8 batch 28/89 processed 7,368 batch-loss 6.1149 epoch-elapsed 0h01m12s total-elapsed 0h33m13s\n",
            "epoch 8 batch 29/89 processed 7,378 batch-loss 6.5097 epoch-elapsed 0h01m15s total-elapsed 0h33m15s\n",
            "epoch 8 batch 30/89 processed 7,388 batch-loss 7.8417 epoch-elapsed 0h01m17s total-elapsed 0h33m18s\n",
            "epoch 8 batch 31/89 processed 7,398 batch-loss 7.7493 epoch-elapsed 0h01m20s total-elapsed 0h33m20s\n",
            "epoch 8 batch 32/89 processed 7,408 batch-loss 10.4487 epoch-elapsed 0h01m23s total-elapsed 0h33m23s\n",
            "epoch 8 batch 33/89 processed 7,418 batch-loss 7.4804 epoch-elapsed 0h01m25s total-elapsed 0h33m25s\n",
            "epoch 8 batch 34/89 processed 7,428 batch-loss 9.7369 epoch-elapsed 0h01m27s total-elapsed 0h33m28s\n",
            "epoch 8 batch 35/89 processed 7,438 batch-loss 7.4774 epoch-elapsed 0h01m30s total-elapsed 0h33m30s\n",
            "epoch 8 batch 36/89 processed 7,448 batch-loss 5.1314 epoch-elapsed 0h01m32s total-elapsed 0h33m32s\n",
            "epoch 8 batch 37/89 processed 7,458 batch-loss 7.0530 epoch-elapsed 0h01m35s total-elapsed 0h33m35s\n",
            "epoch 8 batch 38/89 processed 7,468 batch-loss 10.4473 epoch-elapsed 0h01m38s total-elapsed 0h33m38s\n",
            "epoch 8 batch 39/89 processed 7,478 batch-loss 10.5156 epoch-elapsed 0h01m41s total-elapsed 0h33m41s\n",
            "epoch 8 batch 40/89 processed 7,488 batch-loss 11.1772 epoch-elapsed 0h01m45s total-elapsed 0h33m45s\n",
            "epoch 8 batch 41/89 processed 7,498 batch-loss 7.8997 epoch-elapsed 0h01m47s total-elapsed 0h33m48s\n",
            "epoch 8 batch 42/89 processed 7,508 batch-loss 6.5106 epoch-elapsed 0h01m49s total-elapsed 0h33m50s\n",
            "epoch 8 batch 43/89 processed 7,518 batch-loss 2.0215 epoch-elapsed 0h01m50s total-elapsed 0h33m51s\n",
            "epoch 8 batch 44/89 processed 7,528 batch-loss 9.2228 epoch-elapsed 0h01m53s total-elapsed 0h33m54s\n",
            "epoch 8 batch 45/89 processed 7,538 batch-loss 3.1227 epoch-elapsed 0h01m55s total-elapsed 0h33m56s\n",
            "epoch 8 batch 46/89 processed 7,548 batch-loss 5.6193 epoch-elapsed 0h01m57s total-elapsed 0h33m58s\n",
            "epoch 8 batch 47/89 processed 7,558 batch-loss 9.9941 epoch-elapsed 0h02m00s total-elapsed 0h34m01s\n",
            "epoch 8 batch 48/89 processed 7,568 batch-loss 6.5977 epoch-elapsed 0h02m02s total-elapsed 0h34m03s\n",
            "epoch 8 batch 49/89 processed 7,578 batch-loss 8.8727 epoch-elapsed 0h02m06s total-elapsed 0h34m06s\n",
            "epoch 8 batch 50/89 processed 7,588 batch-loss 8.9234 epoch-elapsed 0h02m08s total-elapsed 0h34m09s\n",
            "epoch 8 batch 51/89 processed 7,598 batch-loss 5.9993 epoch-elapsed 0h02m11s total-elapsed 0h34m11s\n",
            "epoch 8 batch 52/89 processed 7,608 batch-loss 8.9564 epoch-elapsed 0h02m15s total-elapsed 0h34m15s\n",
            "epoch 8 batch 53/89 processed 7,618 batch-loss 4.6759 epoch-elapsed 0h02m17s total-elapsed 0h34m18s\n",
            "epoch 8 batch 54/89 processed 7,628 batch-loss 9.5470 epoch-elapsed 0h02m20s total-elapsed 0h34m20s\n",
            "epoch 8 batch 55/89 processed 7,638 batch-loss 8.3841 epoch-elapsed 0h02m22s total-elapsed 0h34m22s\n",
            "epoch 8 batch 56/89 processed 7,648 batch-loss 11.2319 epoch-elapsed 0h02m25s total-elapsed 0h34m26s\n",
            "epoch 8 batch 57/89 processed 7,658 batch-loss 5.0164 epoch-elapsed 0h02m28s total-elapsed 0h34m28s\n",
            "epoch 8 batch 58/89 processed 7,668 batch-loss 14.8136 epoch-elapsed 0h02m32s total-elapsed 0h34m33s\n",
            "epoch 8 batch 59/89 processed 7,678 batch-loss 15.2073 epoch-elapsed 0h02m36s total-elapsed 0h34m37s\n",
            "epoch 8 batch 60/89 processed 7,688 batch-loss 7.0545 epoch-elapsed 0h02m38s total-elapsed 0h34m39s\n",
            "epoch 8 batch 61/89 processed 7,698 batch-loss 8.8634 epoch-elapsed 0h02m41s total-elapsed 0h34m42s\n",
            "epoch 8 batch 62/89 processed 7,708 batch-loss 7.0225 epoch-elapsed 0h02m44s total-elapsed 0h34m44s\n",
            "epoch 8 batch 63/89 processed 7,718 batch-loss 7.9874 epoch-elapsed 0h02m46s total-elapsed 0h34m47s\n",
            "epoch 8 batch 64/89 processed 7,728 batch-loss 12.0419 epoch-elapsed 0h02m50s total-elapsed 0h34m51s\n",
            "epoch 8 batch 65/89 processed 7,738 batch-loss 7.4426 epoch-elapsed 0h02m52s total-elapsed 0h34m53s\n",
            "epoch 8 batch 66/89 processed 7,748 batch-loss 7.6388 epoch-elapsed 0h02m55s total-elapsed 0h34m56s\n",
            "epoch 8 batch 67/89 processed 7,758 batch-loss 9.0456 epoch-elapsed 0h02m57s total-elapsed 0h34m58s\n",
            "epoch 8 batch 68/89 processed 7,768 batch-loss 13.0271 epoch-elapsed 0h03m00s total-elapsed 0h35m01s\n",
            "epoch 8 batch 69/89 processed 7,778 batch-loss 12.0155 epoch-elapsed 0h03m04s total-elapsed 0h35m05s\n",
            "epoch 8 batch 70/89 processed 7,788 batch-loss 5.9613 epoch-elapsed 0h03m07s total-elapsed 0h35m07s\n",
            "epoch 8 batch 71/89 processed 7,798 batch-loss 4.7176 epoch-elapsed 0h03m09s total-elapsed 0h35m09s\n",
            "epoch 8 batch 72/89 processed 7,808 batch-loss 10.9061 epoch-elapsed 0h03m13s total-elapsed 0h35m13s\n",
            "epoch 8 batch 73/89 processed 7,818 batch-loss 4.7292 epoch-elapsed 0h03m15s total-elapsed 0h35m15s\n",
            "epoch 8 batch 74/89 processed 7,828 batch-loss 7.3831 epoch-elapsed 0h03m17s total-elapsed 0h35m18s\n",
            "epoch 8 batch 75/89 processed 7,838 batch-loss 5.8631 epoch-elapsed 0h03m19s total-elapsed 0h35m20s\n",
            "epoch 8 batch 76/89 processed 7,848 batch-loss 8.0376 epoch-elapsed 0h03m21s total-elapsed 0h35m22s\n",
            "epoch 8 batch 77/89 processed 7,858 batch-loss 6.2168 epoch-elapsed 0h03m24s total-elapsed 0h35m24s\n",
            "epoch 8 batch 78/89 processed 7,868 batch-loss 9.4904 epoch-elapsed 0h03m27s total-elapsed 0h35m27s\n",
            "epoch 8 batch 79/89 processed 7,878 batch-loss 6.6125 epoch-elapsed 0h03m29s total-elapsed 0h35m29s\n",
            "epoch 8 batch 80/89 processed 7,888 batch-loss 6.6310 epoch-elapsed 0h03m31s total-elapsed 0h35m31s\n",
            "epoch 8 batch 81/89 processed 7,898 batch-loss 10.4269 epoch-elapsed 0h03m34s total-elapsed 0h35m35s\n",
            "epoch 8 batch 82/89 processed 7,908 batch-loss 5.9108 epoch-elapsed 0h03m36s total-elapsed 0h35m37s\n",
            "epoch 8 batch 83/89 processed 7,918 batch-loss 11.1040 epoch-elapsed 0h03m39s total-elapsed 0h35m39s\n",
            "epoch 8 batch 84/89 processed 7,928 batch-loss 6.2273 epoch-elapsed 0h03m42s total-elapsed 0h35m42s\n",
            "epoch 8 batch 85/89 processed 7,938 batch-loss 17.9737 epoch-elapsed 0h03m45s total-elapsed 0h35m45s\n",
            "epoch 8 batch 86/89 processed 7,948 batch-loss 7.8237 epoch-elapsed 0h03m48s total-elapsed 0h35m48s\n",
            "epoch 8 batch 87/89 processed 7,958 batch-loss 7.8071 epoch-elapsed 0h03m51s total-elapsed 0h35m51s\n",
            "epoch 8 batch 88/89 processed 7,968 batch-loss 10.9282 epoch-elapsed 0h03m53s total-elapsed 0h35m54s\n",
            "epoch 8 batch 89/89 processed 7,974 batch-loss 13.6222 epoch-elapsed 0h03m55s total-elapsed 0h35m55s\n",
            "epoch 9 batch 1/89 processed 7,984 batch-loss 6.6449 epoch-elapsed 0h00m03s total-elapsed 0h35m58s\n",
            "epoch 9 batch 2/89 processed 7,994 batch-loss 5.1866 epoch-elapsed 0h00m05s total-elapsed 0h36m01s\n",
            "epoch 9 batch 3/89 processed 8,004 batch-loss 3.8229 epoch-elapsed 0h00m07s total-elapsed 0h36m02s\n",
            "epoch 9 batch 4/89 processed 8,014 batch-loss 11.2343 epoch-elapsed 0h00m10s total-elapsed 0h36m06s\n",
            "epoch 9 batch 5/89 processed 8,024 batch-loss 10.2055 epoch-elapsed 0h00m14s total-elapsed 0h36m10s\n",
            "epoch 9 batch 6/89 processed 8,034 batch-loss 10.1149 epoch-elapsed 0h00m17s total-elapsed 0h36m13s\n",
            "epoch 9 batch 7/89 processed 8,044 batch-loss 11.5994 epoch-elapsed 0h00m21s total-elapsed 0h36m17s\n",
            "epoch 9 batch 8/89 processed 8,054 batch-loss 7.9786 epoch-elapsed 0h00m24s total-elapsed 0h36m19s\n",
            "epoch 9 batch 9/89 processed 8,064 batch-loss 11.7340 epoch-elapsed 0h00m27s total-elapsed 0h36m23s\n",
            "epoch 9 batch 10/89 processed 8,074 batch-loss 4.9500 epoch-elapsed 0h00m29s total-elapsed 0h36m25s\n",
            "epoch 9 batch 11/89 processed 8,084 batch-loss 5.3533 epoch-elapsed 0h00m31s total-elapsed 0h36m27s\n",
            "epoch 9 batch 12/89 processed 8,094 batch-loss 9.0147 epoch-elapsed 0h00m34s total-elapsed 0h36m29s\n",
            "epoch 9 batch 13/89 processed 8,104 batch-loss 6.4052 epoch-elapsed 0h00m36s total-elapsed 0h36m32s\n",
            "epoch 9 batch 14/89 processed 8,114 batch-loss 7.3156 epoch-elapsed 0h00m38s total-elapsed 0h36m34s\n",
            "epoch 9 batch 15/89 processed 8,124 batch-loss 7.1963 epoch-elapsed 0h00m41s total-elapsed 0h36m36s\n",
            "epoch 9 batch 16/89 processed 8,134 batch-loss 11.1401 epoch-elapsed 0h00m44s total-elapsed 0h36m39s\n",
            "epoch 9 batch 17/89 processed 8,144 batch-loss 5.3575 epoch-elapsed 0h00m46s total-elapsed 0h36m41s\n",
            "epoch 9 batch 18/89 processed 8,154 batch-loss 8.7065 epoch-elapsed 0h00m48s total-elapsed 0h36m43s\n",
            "epoch 9 batch 19/89 processed 8,164 batch-loss 13.5336 epoch-elapsed 0h00m52s total-elapsed 0h36m47s\n",
            "epoch 9 batch 20/89 processed 8,174 batch-loss 3.7138 epoch-elapsed 0h00m54s total-elapsed 0h36m50s\n",
            "epoch 9 batch 21/89 processed 8,184 batch-loss 5.6428 epoch-elapsed 0h00m56s total-elapsed 0h36m52s\n",
            "epoch 9 batch 22/89 processed 8,194 batch-loss 7.1262 epoch-elapsed 0h00m59s total-elapsed 0h36m55s\n",
            "epoch 9 batch 23/89 processed 8,204 batch-loss 10.4571 epoch-elapsed 0h01m02s total-elapsed 0h36m58s\n",
            "epoch 9 batch 24/89 processed 8,214 batch-loss 8.1001 epoch-elapsed 0h01m05s total-elapsed 0h37m01s\n",
            "epoch 9 batch 25/89 processed 8,224 batch-loss 10.3704 epoch-elapsed 0h01m08s total-elapsed 0h37m04s\n",
            "epoch 9 batch 26/89 processed 8,234 batch-loss 5.7108 epoch-elapsed 0h01m11s total-elapsed 0h37m07s\n",
            "epoch 9 batch 27/89 processed 8,244 batch-loss 4.4139 epoch-elapsed 0h01m13s total-elapsed 0h37m09s\n",
            "epoch 9 batch 28/89 processed 8,254 batch-loss 7.1163 epoch-elapsed 0h01m16s total-elapsed 0h37m11s\n",
            "epoch 9 batch 29/89 processed 8,264 batch-loss 8.4934 epoch-elapsed 0h01m18s total-elapsed 0h37m14s\n",
            "epoch 9 batch 30/89 processed 8,274 batch-loss 7.7627 epoch-elapsed 0h01m21s total-elapsed 0h37m17s\n",
            "epoch 9 batch 31/89 processed 8,284 batch-loss 4.7870 epoch-elapsed 0h01m23s total-elapsed 0h37m18s\n",
            "epoch 9 batch 32/89 processed 8,294 batch-loss 10.0407 epoch-elapsed 0h01m26s total-elapsed 0h37m22s\n",
            "epoch 9 batch 33/89 processed 8,304 batch-loss 9.1887 epoch-elapsed 0h01m29s total-elapsed 0h37m25s\n",
            "epoch 9 batch 34/89 processed 8,314 batch-loss 4.6963 epoch-elapsed 0h01m31s total-elapsed 0h37m26s\n",
            "epoch 9 batch 35/89 processed 8,324 batch-loss 6.6456 epoch-elapsed 0h01m33s total-elapsed 0h37m29s\n",
            "epoch 9 batch 36/89 processed 8,334 batch-loss 7.6277 epoch-elapsed 0h01m37s total-elapsed 0h37m32s\n",
            "epoch 9 batch 37/89 processed 8,344 batch-loss 7.5468 epoch-elapsed 0h01m38s total-elapsed 0h37m34s\n",
            "epoch 9 batch 38/89 processed 8,354 batch-loss 8.3323 epoch-elapsed 0h01m41s total-elapsed 0h37m37s\n",
            "epoch 9 batch 39/89 processed 8,364 batch-loss 7.8116 epoch-elapsed 0h01m44s total-elapsed 0h37m40s\n",
            "epoch 9 batch 40/89 processed 8,374 batch-loss 4.1646 epoch-elapsed 0h01m46s total-elapsed 0h37m42s\n",
            "epoch 9 batch 41/89 processed 8,384 batch-loss 7.3028 epoch-elapsed 0h01m49s total-elapsed 0h37m45s\n",
            "epoch 9 batch 42/89 processed 8,394 batch-loss 2.9618 epoch-elapsed 0h01m51s total-elapsed 0h37m46s\n",
            "epoch 9 batch 43/89 processed 8,404 batch-loss 8.3619 epoch-elapsed 0h01m53s total-elapsed 0h37m49s\n",
            "epoch 9 batch 44/89 processed 8,414 batch-loss 7.8894 epoch-elapsed 0h01m55s total-elapsed 0h37m51s\n",
            "epoch 9 batch 45/89 processed 8,424 batch-loss 8.5295 epoch-elapsed 0h01m58s total-elapsed 0h37m54s\n",
            "epoch 9 batch 46/89 processed 8,434 batch-loss 5.8206 epoch-elapsed 0h02m01s total-elapsed 0h37m57s\n",
            "epoch 9 batch 47/89 processed 8,444 batch-loss 7.4544 epoch-elapsed 0h02m04s total-elapsed 0h37m59s\n",
            "epoch 9 batch 48/89 processed 8,454 batch-loss 6.3479 epoch-elapsed 0h02m08s total-elapsed 0h38m03s\n",
            "epoch 9 batch 49/89 processed 8,464 batch-loss 5.3639 epoch-elapsed 0h02m10s total-elapsed 0h38m06s\n",
            "epoch 9 batch 50/89 processed 8,474 batch-loss 6.0066 epoch-elapsed 0h02m12s total-elapsed 0h38m08s\n",
            "epoch 9 batch 51/89 processed 8,484 batch-loss 10.7463 epoch-elapsed 0h02m15s total-elapsed 0h38m11s\n",
            "epoch 9 batch 52/89 processed 8,494 batch-loss 6.2604 epoch-elapsed 0h02m18s total-elapsed 0h38m14s\n",
            "epoch 9 batch 53/89 processed 8,504 batch-loss 7.5514 epoch-elapsed 0h02m21s total-elapsed 0h38m17s\n",
            "epoch 9 batch 54/89 processed 8,514 batch-loss 4.0402 epoch-elapsed 0h02m23s total-elapsed 0h38m19s\n",
            "epoch 9 batch 55/89 processed 8,524 batch-loss 9.7753 epoch-elapsed 0h02m27s total-elapsed 0h38m23s\n",
            "epoch 9 batch 56/89 processed 8,534 batch-loss 5.1654 epoch-elapsed 0h02m30s total-elapsed 0h38m25s\n",
            "epoch 9 batch 57/89 processed 8,544 batch-loss 8.7150 epoch-elapsed 0h02m32s total-elapsed 0h38m28s\n",
            "epoch 9 batch 58/89 processed 8,554 batch-loss 5.4068 epoch-elapsed 0h02m35s total-elapsed 0h38m30s\n",
            "epoch 9 batch 59/89 processed 8,564 batch-loss 5.4706 epoch-elapsed 0h02m37s total-elapsed 0h38m32s\n",
            "epoch 9 batch 60/89 processed 8,574 batch-loss 5.6664 epoch-elapsed 0h02m39s total-elapsed 0h38m35s\n",
            "epoch 9 batch 61/89 processed 8,584 batch-loss 7.5171 epoch-elapsed 0h02m42s total-elapsed 0h38m38s\n",
            "epoch 9 batch 62/89 processed 8,594 batch-loss 6.5916 epoch-elapsed 0h02m45s total-elapsed 0h38m41s\n",
            "epoch 9 batch 63/89 processed 8,604 batch-loss 7.9212 epoch-elapsed 0h02m47s total-elapsed 0h38m43s\n",
            "epoch 9 batch 64/89 processed 8,614 batch-loss 8.8764 epoch-elapsed 0h02m50s total-elapsed 0h38m46s\n",
            "epoch 9 batch 65/89 processed 8,624 batch-loss 9.4548 epoch-elapsed 0h02m53s total-elapsed 0h38m48s\n",
            "epoch 9 batch 66/89 processed 8,634 batch-loss 5.1608 epoch-elapsed 0h02m55s total-elapsed 0h38m51s\n",
            "epoch 9 batch 67/89 processed 8,644 batch-loss 7.7338 epoch-elapsed 0h02m57s total-elapsed 0h38m53s\n",
            "epoch 9 batch 68/89 processed 8,654 batch-loss 4.8755 epoch-elapsed 0h03m00s total-elapsed 0h38m56s\n",
            "epoch 9 batch 69/89 processed 8,664 batch-loss 6.0073 epoch-elapsed 0h03m03s total-elapsed 0h38m58s\n",
            "epoch 9 batch 70/89 processed 8,674 batch-loss 2.4595 epoch-elapsed 0h03m04s total-elapsed 0h39m00s\n",
            "epoch 9 batch 71/89 processed 8,684 batch-loss 12.7130 epoch-elapsed 0h03m08s total-elapsed 0h39m04s\n",
            "epoch 9 batch 72/89 processed 8,694 batch-loss 6.0060 epoch-elapsed 0h03m11s total-elapsed 0h39m06s\n",
            "epoch 9 batch 73/89 processed 8,704 batch-loss 6.7014 epoch-elapsed 0h03m13s total-elapsed 0h39m09s\n",
            "epoch 9 batch 74/89 processed 8,714 batch-loss 8.3256 epoch-elapsed 0h03m16s total-elapsed 0h39m12s\n",
            "epoch 9 batch 75/89 processed 8,724 batch-loss 6.8848 epoch-elapsed 0h03m19s total-elapsed 0h39m15s\n",
            "epoch 9 batch 76/89 processed 8,734 batch-loss 6.7597 epoch-elapsed 0h03m22s total-elapsed 0h39m18s\n",
            "epoch 9 batch 77/89 processed 8,744 batch-loss 17.2792 epoch-elapsed 0h03m26s total-elapsed 0h39m22s\n",
            "epoch 9 batch 78/89 processed 8,754 batch-loss 7.4999 epoch-elapsed 0h03m29s total-elapsed 0h39m25s\n",
            "epoch 9 batch 79/89 processed 8,764 batch-loss 10.9742 epoch-elapsed 0h03m31s total-elapsed 0h39m27s\n",
            "epoch 9 batch 80/89 processed 8,774 batch-loss 9.8956 epoch-elapsed 0h03m34s total-elapsed 0h39m30s\n",
            "epoch 9 batch 81/89 processed 8,784 batch-loss 6.4950 epoch-elapsed 0h03m37s total-elapsed 0h39m33s\n",
            "epoch 9 batch 82/89 processed 8,794 batch-loss 5.4656 epoch-elapsed 0h03m40s total-elapsed 0h39m35s\n",
            "epoch 9 batch 83/89 processed 8,804 batch-loss 4.2173 epoch-elapsed 0h03m41s total-elapsed 0h39m37s\n",
            "epoch 9 batch 84/89 processed 8,814 batch-loss 7.1423 epoch-elapsed 0h03m44s total-elapsed 0h39m39s\n",
            "epoch 9 batch 85/89 processed 8,824 batch-loss 6.4818 epoch-elapsed 0h03m47s total-elapsed 0h39m43s\n",
            "epoch 9 batch 86/89 processed 8,834 batch-loss 4.9273 epoch-elapsed 0h03m49s total-elapsed 0h39m44s\n",
            "epoch 9 batch 87/89 processed 8,844 batch-loss 2.5158 epoch-elapsed 0h03m50s total-elapsed 0h39m46s\n",
            "epoch 9 batch 88/89 processed 8,854 batch-loss 5.2137 epoch-elapsed 0h03m52s total-elapsed 0h39m48s\n",
            "epoch 9 batch 89/89 processed 8,860 batch-loss 6.5996 epoch-elapsed 0h03m54s total-elapsed 0h39m49s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from src.util import format_elapsed\n",
        "\n",
        "np.random.seed(1)\n",
        "trainer = dy.AdamTrainer(model)\n",
        "total_processed = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(10):\n",
        "    np.random.shuffle(train_parse)\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for start_index in range(0, len(train_parse), batch_size):\n",
        "        dy.renew_cg()\n",
        "        batch_losses = []\n",
        "        \n",
        "        for gold_tree in train_parse[start_index:start_index + batch_size]:\n",
        "            sentence = []\n",
        "            for leaf in gold_tree.leaves():\n",
        "              sentence.append((leaf.tag, leaf.word))\n",
        "            loss = hinge_loss(sentence, gold_tree)\n",
        "            batch_losses.append(loss)\n",
        "            total_processed += 1        \n",
        "\n",
        "        batch_loss = dy.average(batch_losses)\n",
        "        batch_loss_value = batch_loss.scalar_value()\n",
        "        batch_loss.backward()\n",
        "        trainer.update()\n",
        "\n",
        "        print(\n",
        "            \"epoch {:,} \"\n",
        "            \"batch {:,}/{:,} \"\n",
        "            \"processed {:,} \"\n",
        "            \"batch-loss {:.4f} \"\n",
        "            \"epoch-elapsed {} \"\n",
        "            \"total-elapsed {}\".format(\n",
        "                epoch,\n",
        "                start_index // batch_size + 1,\n",
        "                int(np.ceil(len(train_parse) / batch_size)),\n",
        "                total_processed,\n",
        "                batch_loss_value,\n",
        "                format_elapsed(epoch_start_time),\n",
        "                format_elapsed(start_time),\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "907f3df6",
      "metadata": {
        "id": "907f3df6"
      },
      "source": [
        "### Evaluating the model\n",
        "Evaluate the model and report the Recall, Precision, and F-Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eac5620",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eac5620",
        "outputId": "62050653-cf37-483d-cdd2-5ffb457fbf32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev-fscore (Recall=74.99, Precision=76.17, FScore=75.57) \n"
          ]
        }
      ],
      "source": [
        "from src import evaluate\n",
        "\n",
        "evalb_dir = \"EVALB/\"\n",
        "!chmod +x EVALB/evalb\n",
        "\n",
        "test_predicted = []\n",
        "for tree in test_treebank:\n",
        "    dy.renew_cg()\n",
        "    sentence = [(leaf.tag, leaf.word) for leaf in tree.leaves()]\n",
        "    predicted, _ = parse(sentence, None, False)\n",
        "    test_predicted.append(predicted.convert())\n",
        "\n",
        "test_fscore = evaluate.evalb(evalb_dir, test_treebank, test_predicted)\n",
        "\n",
        "print(f\"dev-fscore {test_fscore} \")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "parsing",
      "language": "python",
      "name": "parsing"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
